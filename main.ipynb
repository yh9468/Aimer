{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/timeseriesAI/tsai/blob/master/tutorial_nbs/10_Time_Series_Classification_and_Regression_with_MiniRocket.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base & visualization\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "#sklearn module & utils\n",
    "from sklearn.model_selection import StratifiedKFold , KFold, train_test_split, cross_val_score, cross_validate\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# hyperparameter\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "#Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#Modeling\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error\n",
    "from sklearn.impute import KNNImputer\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor, TabModel, TabNetClassifier\n",
    "from pytorch_tabnet.augmentations import ClassificationSMOTE\n",
    "DATA_PATH = Path('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "SEED = 25\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train:\n",
    "    if train[col].nunique() < 2:\n",
    "        train.drop(columns=col, inplace=True)\n",
    "        test.drop(columns=col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset/train.csv')\n",
    "test = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "dup = ~train.T.duplicated()\n",
    "train = train.loc[:, dup]\n",
    "test = test.loc[:, dup]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "imputer = KNNImputer()\n",
    "\n",
    "num_features = T.select_dtypes(exclude=['object']).columns.to_list()\n",
    "T[num_features] = scaler.fit_transform(T[num_features])\n",
    "T[num_features] = imputer.fit_transform(T[num_features])\n",
    "\n",
    "num_features = A.select_dtypes(exclude=['object']).columns.to_list()\n",
    "A[num_features] = scaler.fit_transform(A[num_features])\n",
    "A[num_features] = imputer.fit_transform(A[num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(349, 442) (249, 1058)\n"
     ]
    }
   ],
   "source": [
    "print(T.shape, A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = pd.merge(T, A, how='outer').sort_values(\"PRODUCT_ID\").reset_index(drop=True)\n",
    "new_train.drop(columns=[\"TIMESTAMP\", \"PRODUCT_ID\", \"LINE\", \"PRODUCT_CODE\"], inplace=True)\n",
    "tmp = pd.read_csv('dataset/train.csv')\n",
    "y = tmp['Y_Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset/train.csv')\n",
    "test = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "train.drop(columns=[\"PRODUCT_ID\", \"TIMESTAMP\", 'LINE', 'PRODUCT_CODE'], inplace=True)\n",
    "test.drop(columns=[\"PRODUCT_ID\", \"TIMESTAMP\", 'LINE', 'PRODUCT_CODE'], inplace=True)\n",
    "y = train['Y_Class']\n",
    "\n",
    "num_features = test.select_dtypes(exclude=['object']).columns.to_list()\n",
    "\n",
    "#for col in num_features:\n",
    "#    train[col] = train[col].fillna(train[col].median())\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#scaler = QuantileTransformer()\n",
    "train[num_features] = scaler.fit_transform(train[num_features])\n",
    "test[num_features] = scaler.transform(test[num_features])\n",
    "\n",
    "X = train.drop(columns=['Y_Class', 'Y_Quality'])\n",
    "X_test = test\n",
    "\n",
    "#from math import *\n",
    "corr = pd.read_csv('correlation/correlation.csv')\n",
    "# Y_Quality 제거\n",
    "corr = corr.iloc[:-1,:]\n",
    "important = list(corr[abs(corr['correlation'])>=0.1]['feature'])\n",
    "#important\n",
    "X = X[important]\n",
    "X_test = X_test[important]\n",
    "\n",
    "dup = ~X.T.duplicated()\n",
    "X = X.loc[:, dup]\n",
    "X_test = X_test.loc[:, dup]\n",
    "\n",
    "#num_features = X_test.select_dtypes(exclude=['object']).columns.to_list()\n",
    "#scaler = StandardScaler()\n",
    "#X[num_features] = scaler.fit_transform(X[num_features])\n",
    "#X_test[num_features] = scaler.transform(X_test[num_features])\n",
    "\n",
    "imputer = KNNImputer()\n",
    "X = imputer.fit_transform(X)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_macroF1_lgb(truth, predictions):  \n",
    "    pred_labels = predictions.reshape(len(np.unique(truth)),-1).argmax(axis=0)\n",
    "    f1 = f1_score(truth, pred_labels, average='macro')\n",
    "    return ('macroF1', f1, True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-22 13:50:08,256]\u001b[0m A new study created in memory with name: no-name-6585d6f0-6ed1-4763-96d2-d0ddbbde0c5e\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:50:14,123]\u001b[0m Trial 0 finished with value: 0.5772307350648576 and parameters: {'num_leaves': 39, 'learning_rate': 0.014606758782620575, 'class_weight': 'balanced', 'min_child_samples': 12}. Best is trial 0 with value: 0.5772307350648576.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:50:17,780]\u001b[0m Trial 1 finished with value: 0.5692617020270537 and parameters: {'num_leaves': 11, 'learning_rate': 0.00664049196977075, 'class_weight': 'balanced', 'min_child_samples': 8}. Best is trial 0 with value: 0.5772307350648576.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:50:22,165]\u001b[0m Trial 2 finished with value: 0.5689833763088578 and parameters: {'num_leaves': 28, 'learning_rate': 0.007502778397963552, 'class_weight': 'balanced', 'min_child_samples': 19}. Best is trial 0 with value: 0.5772307350648576.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:50:26,651]\u001b[0m Trial 3 finished with value: 0.608806353949773 and parameters: {'num_leaves': 15, 'learning_rate': 0.006378689432796448, 'class_weight': 'balanced', 'min_child_samples': 7}. Best is trial 3 with value: 0.608806353949773.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:50:30,712]\u001b[0m Trial 4 finished with value: 0.5781284419864732 and parameters: {'num_leaves': 18, 'learning_rate': 0.014821434292996908, 'class_weight': 'balanced', 'min_child_samples': 9}. Best is trial 3 with value: 0.608806353949773.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:50:35,984]\u001b[0m Trial 5 finished with value: 0.5649716312045013 and parameters: {'num_leaves': 20, 'learning_rate': 0.00448851057035432, 'class_weight': 'balanced', 'min_child_samples': 23}. Best is trial 3 with value: 0.608806353949773.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:50:41,348]\u001b[0m Trial 6 finished with value: 0.6294713672849244 and parameters: {'num_leaves': 15, 'learning_rate': 0.04707052221509217, 'class_weight': 'balanced', 'min_child_samples': 17}. Best is trial 6 with value: 0.6294713672849244.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:50:45,949]\u001b[0m Trial 7 finished with value: 0.5719889767656273 and parameters: {'num_leaves': 20, 'learning_rate': 0.005835744324508943, 'class_weight': 'balanced', 'min_child_samples': 30}. Best is trial 6 with value: 0.6294713672849244.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:50:51,720]\u001b[0m Trial 8 finished with value: 0.6020665805961938 and parameters: {'num_leaves': 20, 'learning_rate': 0.013125218701581445, 'class_weight': 'balanced', 'min_child_samples': 5}. Best is trial 6 with value: 0.6294713672849244.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:50:57,407]\u001b[0m Trial 9 finished with value: 0.5595450027140316 and parameters: {'num_leaves': 30, 'learning_rate': 0.006950356725267332, 'class_weight': 'balanced', 'min_child_samples': 16}. Best is trial 6 with value: 0.6294713672849244.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:51:01,482]\u001b[0m Trial 10 finished with value: 0.5989941676864083 and parameters: {'num_leaves': 8, 'learning_rate': 0.06500375185998494, 'class_weight': 'balanced', 'min_child_samples': 23}. Best is trial 6 with value: 0.6294713672849244.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:51:05,803]\u001b[0m Trial 11 finished with value: 0.5518714216359115 and parameters: {'num_leaves': 13, 'learning_rate': 0.0014471190870959784, 'class_weight': 'balanced', 'min_child_samples': 15}. Best is trial 6 with value: 0.6294713672849244.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:51:09,636]\u001b[0m Trial 12 finished with value: 0.5969552742303972 and parameters: {'num_leaves': 12, 'learning_rate': 0.09410827504508622, 'class_weight': 'balanced', 'min_child_samples': 22}. Best is trial 6 with value: 0.6294713672849244.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:51:14,778]\u001b[0m Trial 13 finished with value: 0.5814848146863975 and parameters: {'num_leaves': 15, 'learning_rate': 0.0371068053785125, 'class_weight': 'balanced', 'min_child_samples': 30}. Best is trial 6 with value: 0.6294713672849244.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:51:18,949]\u001b[0m Trial 14 finished with value: 0.5851494460165784 and parameters: {'num_leaves': 9, 'learning_rate': 0.027683526815554308, 'class_weight': 'balanced', 'min_child_samples': 11}. Best is trial 6 with value: 0.6294713672849244.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:51:23,229]\u001b[0m Trial 15 finished with value: 0.5746157534004984 and parameters: {'num_leaves': 16, 'learning_rate': 0.02722778239922366, 'class_weight': 'balanced', 'min_child_samples': 5}. Best is trial 6 with value: 0.6294713672849244.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:51:27,235]\u001b[0m Trial 16 finished with value: 0.5614589019932403 and parameters: {'num_leaves': 10, 'learning_rate': 0.0030122771791973014, 'class_weight': 'balanced', 'min_child_samples': 19}. Best is trial 6 with value: 0.6294713672849244.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:51:31,874]\u001b[0m Trial 17 finished with value: 0.59403452454054 and parameters: {'num_leaves': 14, 'learning_rate': 0.05340670372005852, 'class_weight': 'balanced', 'min_child_samples': 26}. Best is trial 6 with value: 0.6294713672849244.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:51:36,033]\u001b[0m Trial 18 finished with value: 0.5750825400725845 and parameters: {'num_leaves': 12, 'learning_rate': 0.020370088366177617, 'class_weight': 'balanced', 'min_child_samples': 13}. Best is trial 6 with value: 0.6294713672849244.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:51:39,424]\u001b[0m Trial 19 finished with value: 0.5966891143867527 and parameters: {'num_leaves': 8, 'learning_rate': 0.009671280622876623, 'class_weight': 'balanced', 'min_child_samples': 8}. Best is trial 6 with value: 0.6294713672849244.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:51:43,426]\u001b[0m Trial 20 finished with value: 0.630357151158346 and parameters: {'num_leaves': 10, 'learning_rate': 0.09932040702900186, 'class_weight': 'balanced', 'min_child_samples': 14}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:51:47,160]\u001b[0m Trial 21 finished with value: 0.5857683256585825 and parameters: {'num_leaves': 10, 'learning_rate': 0.08771088338997571, 'class_weight': 'balanced', 'min_child_samples': 15}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:51:51,804]\u001b[0m Trial 22 finished with value: 0.5669735652027812 and parameters: {'num_leaves': 14, 'learning_rate': 0.04665122616464576, 'class_weight': 'balanced', 'min_child_samples': 19}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:51:56,674]\u001b[0m Trial 23 finished with value: 0.6123233496054137 and parameters: {'num_leaves': 11, 'learning_rate': 0.07041454206557345, 'class_weight': 'balanced', 'min_child_samples': 11}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:52:00,576]\u001b[0m Trial 24 finished with value: 0.6135764375412729 and parameters: {'num_leaves': 10, 'learning_rate': 0.06523227035963147, 'class_weight': 'balanced', 'min_child_samples': 14}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:52:04,125]\u001b[0m Trial 25 finished with value: 0.5975171367573763 and parameters: {'num_leaves': 9, 'learning_rate': 0.0984282855756433, 'class_weight': 'balanced', 'min_child_samples': 17}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:52:08,949]\u001b[0m Trial 26 finished with value: 0.6163880934455527 and parameters: {'num_leaves': 12, 'learning_rate': 0.05946941340264466, 'class_weight': 'balanced', 'min_child_samples': 13}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:52:14,033]\u001b[0m Trial 27 finished with value: 0.5659063441218982 and parameters: {'num_leaves': 17, 'learning_rate': 0.04593959629087437, 'class_weight': 'balanced', 'min_child_samples': 18}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:52:19,769]\u001b[0m Trial 28 finished with value: 0.6025846751646502 and parameters: {'num_leaves': 13, 'learning_rate': 0.03346881018301559, 'class_weight': 'balanced', 'min_child_samples': 10}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:52:23,600]\u001b[0m Trial 29 finished with value: 0.6101946508859719 and parameters: {'num_leaves': 12, 'learning_rate': 0.044455336775076064, 'class_weight': 'balanced', 'min_child_samples': 13}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:52:28,721]\u001b[0m Trial 30 finished with value: 0.6110542289496985 and parameters: {'num_leaves': 49, 'learning_rate': 0.07033640701537497, 'class_weight': 'balanced', 'min_child_samples': 21}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:52:32,515]\u001b[0m Trial 31 finished with value: 0.599985836021687 and parameters: {'num_leaves': 9, 'learning_rate': 0.06883991545402032, 'class_weight': 'balanced', 'min_child_samples': 14}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:52:36,332]\u001b[0m Trial 32 finished with value: 0.6064027959014264 and parameters: {'num_leaves': 11, 'learning_rate': 0.05680105784529559, 'class_weight': 'balanced', 'min_child_samples': 13}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:52:40,308]\u001b[0m Trial 33 finished with value: 0.6119010718652799 and parameters: {'num_leaves': 10, 'learning_rate': 0.07834563779254647, 'class_weight': 'balanced', 'min_child_samples': 16}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:52:44,082]\u001b[0m Trial 34 finished with value: 0.5914998718057445 and parameters: {'num_leaves': 8, 'learning_rate': 0.09741008048580219, 'class_weight': 'balanced', 'min_child_samples': 12}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:52:48,036]\u001b[0m Trial 35 finished with value: 0.5820661842246047 and parameters: {'num_leaves': 11, 'learning_rate': 0.055734698121317865, 'class_weight': 'balanced', 'min_child_samples': 17}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:52:54,039]\u001b[0m Trial 36 finished with value: 0.6135361562328466 and parameters: {'num_leaves': 17, 'learning_rate': 0.03689921764630685, 'class_weight': 'balanced', 'min_child_samples': 15}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:52:57,365]\u001b[0m Trial 37 finished with value: 0.5693037697825696 and parameters: {'num_leaves': 14, 'learning_rate': 0.058321253594048675, 'class_weight': 'balanced', 'min_child_samples': 20}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:53:03,180]\u001b[0m Trial 38 finished with value: 0.607389887383823 and parameters: {'num_leaves': 22, 'learning_rate': 0.0742378768253116, 'class_weight': 'balanced', 'min_child_samples': 9}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:53:08,708]\u001b[0m Trial 39 finished with value: 0.5817707990854798 and parameters: {'num_leaves': 15, 'learning_rate': 0.018043185455919444, 'class_weight': 'balanced', 'min_child_samples': 11}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:53:13,875]\u001b[0m Trial 40 finished with value: 0.6161374184567842 and parameters: {'num_leaves': 13, 'learning_rate': 0.04247257184335362, 'class_weight': 'balanced', 'min_child_samples': 14}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:53:19,046]\u001b[0m Trial 41 finished with value: 0.6188061220308259 and parameters: {'num_leaves': 13, 'learning_rate': 0.04524822734944815, 'class_weight': 'balanced', 'min_child_samples': 14}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:53:24,933]\u001b[0m Trial 42 finished with value: 0.6102669622894162 and parameters: {'num_leaves': 13, 'learning_rate': 0.042927110039448754, 'class_weight': 'balanced', 'min_child_samples': 16}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:53:30,794]\u001b[0m Trial 43 finished with value: 0.5929175157778219 and parameters: {'num_leaves': 18, 'learning_rate': 0.028130138484370706, 'class_weight': 'balanced', 'min_child_samples': 14}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:53:35,402]\u001b[0m Trial 44 finished with value: 0.585106942796136 and parameters: {'num_leaves': 12, 'learning_rate': 0.050069799591805395, 'class_weight': 'balanced', 'min_child_samples': 12}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:53:41,400]\u001b[0m Trial 45 finished with value: 0.5660605403839858 and parameters: {'num_leaves': 15, 'learning_rate': 0.08228886099564543, 'class_weight': 'balanced', 'min_child_samples': 18}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:53:47,492]\u001b[0m Trial 46 finished with value: 0.6085426003907389 and parameters: {'num_leaves': 13, 'learning_rate': 0.0335686218819277, 'class_weight': 'balanced', 'min_child_samples': 7}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:53:53,108]\u001b[0m Trial 47 finished with value: 0.5978539796987723 and parameters: {'num_leaves': 12, 'learning_rate': 0.03993692931058041, 'class_weight': 'balanced', 'min_child_samples': 16}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:53:59,507]\u001b[0m Trial 48 finished with value: 0.6048258153593226 and parameters: {'num_leaves': 22, 'learning_rate': 0.05737564709179432, 'class_weight': 'balanced', 'min_child_samples': 14}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:54:04,395]\u001b[0m Trial 49 finished with value: 0.582559039029397 and parameters: {'num_leaves': 14, 'learning_rate': 0.09980247322608927, 'class_weight': 'balanced', 'min_child_samples': 24}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:54:09,893]\u001b[0m Trial 50 finished with value: 0.6055163325959524 and parameters: {'num_leaves': 16, 'learning_rate': 0.025199195747019898, 'class_weight': 'balanced', 'min_child_samples': 9}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:54:13,883]\u001b[0m Trial 51 finished with value: 0.6014658655592422 and parameters: {'num_leaves': 10, 'learning_rate': 0.06391952330874609, 'class_weight': 'balanced', 'min_child_samples': 12}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:54:18,444]\u001b[0m Trial 52 finished with value: 0.6004002096633939 and parameters: {'num_leaves': 11, 'learning_rate': 0.07835457083454951, 'class_weight': 'balanced', 'min_child_samples': 15}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:54:23,185]\u001b[0m Trial 53 finished with value: 0.6009586348774196 and parameters: {'num_leaves': 10, 'learning_rate': 0.04970478705545463, 'class_weight': 'balanced', 'min_child_samples': 14}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:54:29,026]\u001b[0m Trial 54 finished with value: 0.5760788786672489 and parameters: {'num_leaves': 13, 'learning_rate': 0.06005459340631076, 'class_weight': 'balanced', 'min_child_samples': 17}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:54:33,501]\u001b[0m Trial 55 finished with value: 0.6255670765333655 and parameters: {'num_leaves': 9, 'learning_rate': 0.08290860229497728, 'class_weight': 'balanced', 'min_child_samples': 10}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:54:37,831]\u001b[0m Trial 56 finished with value: 0.6057688208756101 and parameters: {'num_leaves': 9, 'learning_rate': 0.08579346883353282, 'class_weight': 'balanced', 'min_child_samples': 10}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:54:42,044]\u001b[0m Trial 57 finished with value: 0.5839862499457403 and parameters: {'num_leaves': 11, 'learning_rate': 0.03998883855530695, 'class_weight': 'balanced', 'min_child_samples': 7}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:54:46,976]\u001b[0m Trial 58 finished with value: 0.5968099640822836 and parameters: {'num_leaves': 8, 'learning_rate': 0.050178693464067704, 'class_weight': 'balanced', 'min_child_samples': 10}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:54:51,800]\u001b[0m Trial 59 finished with value: 0.6143000344491543 and parameters: {'num_leaves': 12, 'learning_rate': 0.08567268942104654, 'class_weight': 'balanced', 'min_child_samples': 13}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:54:56,165]\u001b[0m Trial 60 finished with value: 0.5934473384523654 and parameters: {'num_leaves': 9, 'learning_rate': 0.06876956936682795, 'class_weight': 'balanced', 'min_child_samples': 12}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:55:01,171]\u001b[0m Trial 61 finished with value: 0.6238565746677142 and parameters: {'num_leaves': 12, 'learning_rate': 0.08552643347795556, 'class_weight': 'balanced', 'min_child_samples': 13}. Best is trial 20 with value: 0.630357151158346.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:55:05,730]\u001b[0m Trial 62 finished with value: 0.6344725266062616 and parameters: {'num_leaves': 13, 'learning_rate': 0.08126145669710355, 'class_weight': 'balanced', 'min_child_samples': 15}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:55:10,698]\u001b[0m Trial 63 finished with value: 0.6043817937763893 and parameters: {'num_leaves': 14, 'learning_rate': 0.08306226022975946, 'class_weight': 'balanced', 'min_child_samples': 11}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:55:14,490]\u001b[0m Trial 64 finished with value: 0.5618795700906241 and parameters: {'num_leaves': 11, 'learning_rate': 0.09871381776459648, 'class_weight': 'balanced', 'min_child_samples': 15}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:55:20,474]\u001b[0m Trial 65 finished with value: 0.6025034678660597 and parameters: {'num_leaves': 15, 'learning_rate': 0.07187780457499293, 'class_weight': 'balanced', 'min_child_samples': 16}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:55:26,591]\u001b[0m Trial 66 finished with value: 0.599620326342091 and parameters: {'num_leaves': 16, 'learning_rate': 0.06408579136208797, 'class_weight': 'balanced', 'min_child_samples': 19}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:55:32,291]\u001b[0m Trial 67 finished with value: 0.6238079731583747 and parameters: {'num_leaves': 12, 'learning_rate': 0.08534330901962914, 'class_weight': 'balanced', 'min_child_samples': 13}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:55:37,463]\u001b[0m Trial 68 finished with value: 0.5645025902736591 and parameters: {'num_leaves': 12, 'learning_rate': 0.0884680603021375, 'class_weight': 'balanced', 'min_child_samples': 18}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:55:41,822]\u001b[0m Trial 69 finished with value: 0.6165212388918099 and parameters: {'num_leaves': 10, 'learning_rate': 0.07417239684543646, 'class_weight': 'balanced', 'min_child_samples': 13}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:55:46,611]\u001b[0m Trial 70 finished with value: 0.5719572131866861 and parameters: {'num_leaves': 14, 'learning_rate': 0.09944398445587452, 'class_weight': 'balanced', 'min_child_samples': 11}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:55:50,685]\u001b[0m Trial 71 finished with value: 0.5971447328510496 and parameters: {'num_leaves': 10, 'learning_rate': 0.07748497977324294, 'class_weight': 'balanced', 'min_child_samples': 13}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:55:55,533]\u001b[0m Trial 72 finished with value: 0.5901816858306498 and parameters: {'num_leaves': 11, 'learning_rate': 0.07648802351875687, 'class_weight': 'balanced', 'min_child_samples': 15}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:56:00,992]\u001b[0m Trial 73 finished with value: 0.6129672156172384 and parameters: {'num_leaves': 10, 'learning_rate': 0.054450354324518106, 'class_weight': 'balanced', 'min_child_samples': 12}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:56:05,793]\u001b[0m Trial 74 finished with value: 0.6087840991135317 and parameters: {'num_leaves': 9, 'learning_rate': 0.06346880635747879, 'class_weight': 'balanced', 'min_child_samples': 17}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:56:10,822]\u001b[0m Trial 75 finished with value: 0.6160219506105661 and parameters: {'num_leaves': 13, 'learning_rate': 0.08989494027507947, 'class_weight': 'balanced', 'min_child_samples': 15}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:56:15,201]\u001b[0m Trial 76 finished with value: 0.587399272183177 and parameters: {'num_leaves': 11, 'learning_rate': 0.07090990874829659, 'class_weight': 'balanced', 'min_child_samples': 9}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:56:19,254]\u001b[0m Trial 77 finished with value: 0.6219993847012116 and parameters: {'num_leaves': 8, 'learning_rate': 0.047335664238337745, 'class_weight': 'balanced', 'min_child_samples': 10}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:56:24,135]\u001b[0m Trial 78 finished with value: 0.6217697574716865 and parameters: {'num_leaves': 8, 'learning_rate': 0.049879440303462884, 'class_weight': 'balanced', 'min_child_samples': 8}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:56:30,054]\u001b[0m Trial 79 finished with value: 0.6122379125918045 and parameters: {'num_leaves': 8, 'learning_rate': 0.048259637391255675, 'class_weight': 'balanced', 'min_child_samples': 8}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:56:35,016]\u001b[0m Trial 80 finished with value: 0.6168753881095321 and parameters: {'num_leaves': 8, 'learning_rate': 0.0549385360149492, 'class_weight': 'balanced', 'min_child_samples': 6}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:56:38,843]\u001b[0m Trial 81 finished with value: 0.602431238393415 and parameters: {'num_leaves': 9, 'learning_rate': 0.06192591242305505, 'class_weight': 'balanced', 'min_child_samples': 10}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:56:44,118]\u001b[0m Trial 82 finished with value: 0.6140527710493835 and parameters: {'num_leaves': 9, 'learning_rate': 0.04556513559045579, 'class_weight': 'balanced', 'min_child_samples': 8}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:56:48,031]\u001b[0m Trial 83 finished with value: 0.6074286886225673 and parameters: {'num_leaves': 8, 'learning_rate': 0.08929119769444642, 'class_weight': 'balanced', 'min_child_samples': 7}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:56:52,903]\u001b[0m Trial 84 finished with value: 0.5966064121024839 and parameters: {'num_leaves': 8, 'learning_rate': 0.0534547408773496, 'class_weight': 'balanced', 'min_child_samples': 5}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:56:58,322]\u001b[0m Trial 85 finished with value: 0.6020494088581334 and parameters: {'num_leaves': 12, 'learning_rate': 0.0656217696527474, 'class_weight': 'balanced', 'min_child_samples': 9}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:57:04,574]\u001b[0m Trial 86 finished with value: 0.613856194730833 and parameters: {'num_leaves': 14, 'learning_rate': 0.07837138627324113, 'class_weight': 'balanced', 'min_child_samples': 14}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:57:10,679]\u001b[0m Trial 87 finished with value: 0.5849395425499384 and parameters: {'num_leaves': 13, 'learning_rate': 0.03718772236078267, 'class_weight': 'balanced', 'min_child_samples': 28}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:57:15,513]\u001b[0m Trial 88 finished with value: 0.6051770832168047 and parameters: {'num_leaves': 12, 'learning_rate': 0.04520772072790688, 'class_weight': 'balanced', 'min_child_samples': 6}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:57:21,561]\u001b[0m Trial 89 finished with value: 0.5907807342579054 and parameters: {'num_leaves': 29, 'learning_rate': 0.09062189985609176, 'class_weight': 'balanced', 'min_child_samples': 13}. Best is trial 62 with value: 0.6344725266062616.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:57:29,666]\u001b[0m Trial 90 finished with value: 0.6357955425601637 and parameters: {'num_leaves': 34, 'learning_rate': 0.058382767995718336, 'class_weight': 'balanced', 'min_child_samples': 12}. Best is trial 90 with value: 0.6357955425601637.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:57:39,207]\u001b[0m Trial 91 finished with value: 0.61737328016965 and parameters: {'num_leaves': 31, 'learning_rate': 0.06817930025385308, 'class_weight': 'balanced', 'min_child_samples': 12}. Best is trial 90 with value: 0.6357955425601637.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:57:46,888]\u001b[0m Trial 92 finished with value: 0.5888920436200993 and parameters: {'num_leaves': 30, 'learning_rate': 0.08133818677728735, 'class_weight': 'balanced', 'min_child_samples': 11}. Best is trial 90 with value: 0.6357955425601637.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:57:55,387]\u001b[0m Trial 93 finished with value: 0.5827347343518989 and parameters: {'num_leaves': 43, 'learning_rate': 0.05072590292415298, 'class_weight': 'balanced', 'min_child_samples': 10}. Best is trial 90 with value: 0.6357955425601637.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:58:01,155]\u001b[0m Trial 94 finished with value: 0.5746136786012169 and parameters: {'num_leaves': 32, 'learning_rate': 0.060509048419922766, 'class_weight': 'balanced', 'min_child_samples': 11}. Best is trial 90 with value: 0.6357955425601637.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:58:06,973]\u001b[0m Trial 95 finished with value: 0.6168083598253917 and parameters: {'num_leaves': 19, 'learning_rate': 0.057586321561449626, 'class_weight': 'balanced', 'min_child_samples': 16}. Best is trial 90 with value: 0.6357955425601637.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:58:13,035]\u001b[0m Trial 96 finished with value: 0.5948684970258178 and parameters: {'num_leaves': 25, 'learning_rate': 0.071846057269278, 'class_weight': 'balanced', 'min_child_samples': 8}. Best is trial 90 with value: 0.6357955425601637.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:58:21,180]\u001b[0m Trial 97 finished with value: 0.6269265929560057 and parameters: {'num_leaves': 33, 'learning_rate': 0.041427016560020465, 'class_weight': 'balanced', 'min_child_samples': 14}. Best is trial 90 with value: 0.6357955425601637.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:58:28,028]\u001b[0m Trial 98 finished with value: 0.6474222877239295 and parameters: {'num_leaves': 34, 'learning_rate': 0.0825133292151492, 'class_weight': 'balanced', 'min_child_samples': 14}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:58:35,642]\u001b[0m Trial 99 finished with value: 0.6065516235499788 and parameters: {'num_leaves': 36, 'learning_rate': 0.09029820131442837, 'class_weight': 'balanced', 'min_child_samples': 14}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:58:42,293]\u001b[0m Trial 100 finished with value: 0.5720596107819513 and parameters: {'num_leaves': 34, 'learning_rate': 0.08264168410050304, 'class_weight': 'balanced', 'min_child_samples': 12}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:58:48,785]\u001b[0m Trial 101 finished with value: 0.6034444944538684 and parameters: {'num_leaves': 33, 'learning_rate': 0.06740595000563937, 'class_weight': 'balanced', 'min_child_samples': 16}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:58:55,590]\u001b[0m Trial 102 finished with value: 0.6101824545851551 and parameters: {'num_leaves': 40, 'learning_rate': 0.09386268135098202, 'class_weight': 'balanced', 'min_child_samples': 15}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:59:02,523]\u001b[0m Trial 103 finished with value: 0.6208255364802777 and parameters: {'num_leaves': 27, 'learning_rate': 0.07761449208204382, 'class_weight': 'balanced', 'min_child_samples': 13}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:59:10,826]\u001b[0m Trial 104 finished with value: 0.5985848028581229 and parameters: {'num_leaves': 35, 'learning_rate': 0.05927973214331605, 'class_weight': 'balanced', 'min_child_samples': 10}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:59:18,553]\u001b[0m Trial 105 finished with value: 0.6178829924670424 and parameters: {'num_leaves': 36, 'learning_rate': 0.052117606086165044, 'class_weight': 'balanced', 'min_child_samples': 14}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:59:28,289]\u001b[0m Trial 106 finished with value: 0.6326635112932292 and parameters: {'num_leaves': 40, 'learning_rate': 0.040634520108666514, 'class_weight': 'balanced', 'min_child_samples': 12}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:59:37,047]\u001b[0m Trial 107 finished with value: 0.6098128271790533 and parameters: {'num_leaves': 39, 'learning_rate': 0.09957171542551432, 'class_weight': 'balanced', 'min_child_samples': 12}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:59:44,700]\u001b[0m Trial 108 finished with value: 0.6018819931925382 and parameters: {'num_leaves': 46, 'learning_rate': 0.040722617068790844, 'class_weight': 'balanced', 'min_child_samples': 13}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:59:51,510]\u001b[0m Trial 109 finished with value: 0.5861408293344568 and parameters: {'num_leaves': 38, 'learning_rate': 0.03314251827468848, 'class_weight': 'balanced', 'min_child_samples': 11}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 13:59:58,678]\u001b[0m Trial 110 finished with value: 0.5871772892305829 and parameters: {'num_leaves': 32, 'learning_rate': 0.07347018838148488, 'class_weight': 'balanced', 'min_child_samples': 17}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 14:00:06,552]\u001b[0m Trial 111 finished with value: 0.6079588209786893 and parameters: {'num_leaves': 41, 'learning_rate': 0.048447883518053056, 'class_weight': 'balanced', 'min_child_samples': 14}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 14:00:13,678]\u001b[0m Trial 112 finished with value: 0.5992619720231834 and parameters: {'num_leaves': 37, 'learning_rate': 0.08286465061060026, 'class_weight': 'balanced', 'min_child_samples': 9}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 14:00:21,959]\u001b[0m Trial 113 finished with value: 0.6064280384052669 and parameters: {'num_leaves': 35, 'learning_rate': 0.06058890099043865, 'class_weight': 'balanced', 'min_child_samples': 15}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 14:00:30,446]\u001b[0m Trial 114 finished with value: 0.6215827153972924 and parameters: {'num_leaves': 43, 'learning_rate': 0.06750837933434371, 'class_weight': 'balanced', 'min_child_samples': 13}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 14:00:37,595]\u001b[0m Trial 115 finished with value: 0.5606297152381319 and parameters: {'num_leaves': 38, 'learning_rate': 0.05400896375430414, 'class_weight': 'balanced', 'min_child_samples': 11}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 14:00:43,783]\u001b[0m Trial 116 finished with value: 0.5698524758110649 and parameters: {'num_leaves': 34, 'learning_rate': 0.043918204462385, 'class_weight': 'balanced', 'min_child_samples': 13}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 14:00:50,323]\u001b[0m Trial 117 finished with value: 0.6083120396448488 and parameters: {'num_leaves': 50, 'learning_rate': 0.08556695335981554, 'class_weight': 'balanced', 'min_child_samples': 20}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 14:00:57,670]\u001b[0m Trial 118 finished with value: 0.6075859329684741 and parameters: {'num_leaves': 37, 'learning_rate': 0.07599980831776151, 'class_weight': 'balanced', 'min_child_samples': 12}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 14:01:04,320]\u001b[0m Trial 119 finished with value: 0.6032454940536782 and parameters: {'num_leaves': 48, 'learning_rate': 0.0643975433298183, 'class_weight': 'balanced', 'min_child_samples': 16}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 14:01:13,591]\u001b[0m Trial 120 finished with value: 0.6065423382066774 and parameters: {'num_leaves': 27, 'learning_rate': 0.09262227929085588, 'class_weight': 'balanced', 'min_child_samples': 12}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 14:01:21,494]\u001b[0m Trial 121 finished with value: 0.6259145325946066 and parameters: {'num_leaves': 41, 'learning_rate': 0.06757884030265, 'class_weight': 'balanced', 'min_child_samples': 13}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[32m[I 2023-02-22 14:01:30,188]\u001b[0m Trial 122 finished with value: 0.6195423608014379 and parameters: {'num_leaves': 40, 'learning_rate': 0.05478681675357036, 'class_weight': 'balanced', 'min_child_samples': 14}. Best is trial 98 with value: 0.6474222877239295.\u001b[0m\n",
      "\u001b[33m[W 2023-02-22 14:01:30,707]\u001b[0m Trial 123 failed with parameters: {'num_leaves': 43, 'learning_rate': 0.048572659826973695, 'class_weight': 'balanced', 'min_child_samples': 13} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dircon/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3773416/3718865927.py\", line 19, in objective\n",
      "    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], eval_metric=evaluate_macroF1_lgb)\n",
      "  File \"/home/dircon/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 1090, in fit\n",
      "    super().fit(\n",
      "  File \"/home/dircon/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 803, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/dircon/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 251, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"/home/dircon/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 3250, in update\n",
      "    _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-02-22 14:01:30,708]\u001b[0m Trial 123 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3773416/3718865927.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSuccessiveHalvingPruner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \"\"\"\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3773416/3718865927.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboost_from_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolsample_bytree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_macroF1_lgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1088\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m             \u001b[0m_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m    804\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    249\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3249\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3250\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   3251\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3252\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "\n",
    "def objective(trial):\n",
    "  params = {\n",
    "    'num_leaves': trial.suggest_int('num_leaves', 8, 50, step=1, log=True), \n",
    "    'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True), \n",
    "    \"metric\": \"multiclass\",\n",
    "    'class_weight': trial.suggest_categorical('class_weight', ['balanced']),\n",
    "    'min_child_samples': trial.suggest_int('min_child_samples', 5, 30, step=1, log=False), \n",
    "    'random_state': SEED\n",
    "  }\n",
    "\n",
    "  kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "  scores = []\n",
    "  for train_index, valid_index in kf.split(new_train, y):\n",
    "    X_train, X_valid = new_train.values[train_index], new_train.values[valid_index]\n",
    "    y_train, y_valid = y.values[train_index], y.values[valid_index]\n",
    "    model = LGBMClassifier(n_estimators=2000, boost_from_average=False, early_stopping_rounds=50, verbose=-1, colsample_bytree=0.7, subsample=0.7, **params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], eval_metric=evaluate_macroF1_lgb)\n",
    "    pred = model.predict(X_valid)\n",
    "    f1 = f1_score(y_valid, pred, average='macro')\n",
    "    scores.append(f1)\n",
    "\n",
    "  return np.mean(scores)\n",
    "\n",
    "study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=SEED), pruner=SuccessiveHalvingPruner())\n",
    "study.optimize(objective, n_trials=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = optim.best_trial\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=10, shuffle = True, random_state = SEED)\n",
    "scores = []\n",
    "models = []\n",
    "# split 개수 스텝 만큼 train, test 데이터셋을 매번 분할\n",
    "for train_index, valid_index in kf.split(train_x, train_y):\n",
    "    X_train, X_test = train_x.iloc[train_index], train_x.iloc[valid_index]\n",
    "    y_train, y_test = train_y[train_index], train_y[valid_index]\n",
    "    params = trial.params\n",
    "    #params['learning_rate'] = 0.20\n",
    "    model = LGBMClassifier(device=\"gpu\", verbose=-1, random_state=SEED, **params)\n",
    "    model.fit(X_train, y_train)\n",
    "    models.append(model)\n",
    "    y_pred = model.predict(X_test) # 예측 라벨\n",
    "    output = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    scores.append(output)\n",
    "\n",
    "print(\"각 분할의 정확도 기록 :\", scores)\n",
    "print(\"평균 정확도 :\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "ensemble = EnsembleVoteClassifier(clfs=models, weights=[1]*10, voting='soft', fit_base_estimators=False)\n",
    "ensemble.fit(None,np.array([0,1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submission file 준비\n",
    "submit = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test predict\n",
    "pred = ensemble.predict(test_x)\n",
    "submit['Y_Class'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e2e4a47e36f0811c316f759d1a92830bb55dbd78977c69f453a1e4981941b515"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
