{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base & visualization\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#sklearn module & utils\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.model_selection import StratifiedKFold , KFold, train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# hyperparameter\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "#Scaling\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler, RobustScaler\n",
    "\n",
    "# Encoding\n",
    "import category_encoders as ce\n",
    "\n",
    "#Sampling\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "#Modeling\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier, VotingClassifier,RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, RidgeClassifierCV\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from pathlib import Path\n",
    "DATA_PATH = Path('dataset')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 자르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_PATH / 'train.csv')\n",
    "test = pd.read_csv(DATA_PATH / 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_TO_idx = (train[\"PRODUCT_CODE\"] == \"T_31\") | (train[\"PRODUCT_CODE\"] == \"O_31\")\n",
    "train_A_idx  = (train[\"PRODUCT_CODE\"] == \"A_31\")\n",
    "test_TO_idx = (test[\"PRODUCT_CODE\"] == \"T_31\") | (test[\"PRODUCT_CODE\"] == \"O_31\")\n",
    "test_A_idx  = (test[\"PRODUCT_CODE\"] == \"A_31\")\n",
    "\n",
    "train_TO = train[train_TO_idx]\n",
    "train_A = train[train_A_idx]\n",
    "test_TO = test[test_TO_idx]\n",
    "test_A = test[test_A_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude(df, df_test):\n",
    "    for col in df:\n",
    "        if df[col].nunique() < 2 and col != \"PRODUCT_CODE\":\n",
    "            df.drop(columns=col, inplace=True)\n",
    "            df_test.drop(columns=col, inplace=True)\n",
    "    return df, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_TO, test_TO = exclude(train_TO, test_TO)\n",
    "train_A, test_A = exclude(train_A, test_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_TO.to_csv(\"split_dataset/train_TO.csv\", index=False)\n",
    "test_TO.to_csv(\"split_dataset/test_TO.csv\", index=False)\n",
    "train_A.to_csv(\"split_dataset/train_A.csv\", index=False)\n",
    "test_A.to_csv(\"split_dataset/test_A.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_TO = pd.read_csv(\"split_dataset/train_TO.csv\")\n",
    "test_TO  = pd.read_csv(\"split_dataset/test_TO.csv\")\n",
    "train_A  = pd.read_csv(\"split_dataset/train_A.csv\")\n",
    "test_A   = pd.read_csv(\"split_dataset/test_A.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(df, df_test):\n",
    "    scaler = StandardScaler()\n",
    "    num_features = df.select_dtypes(exclude=['object']).columns.to_list()[2:]\n",
    "    \n",
    "    df[num_features] = scaler.fit_transform(df[num_features])\n",
    "    df_test[num_features] = scaler.transform(df_test[num_features])\n",
    "    return df, df_test\n",
    "train_TO, test_TO = scale(train_TO, test_TO)\n",
    "train_A, test_A = scale(train_A, test_A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_TO = train_TO.corr()['Y_Quality']\n",
    "corr_A = train_A.corr()['Y_Quality']\n",
    "corr_TO = corr_TO[2:]\n",
    "corr_A = corr_A[2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_TO = corr_TO.sort_values()\n",
    "corr_A = corr_A.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(corr_A).to_csv(\"correlation/correlation_A.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파생변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TO = pd.read_csv(\"split_dataset/train_TO.csv\")\n",
    "test_TO = pd.read_csv(\"split_dataset/test_TO.csv\")\n",
    "\n",
    "X_A = pd.read_csv(\"split_dataset/train_A.csv\")\n",
    "test_A = pd.read_csv(\"split_dataset/test_A.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_TO = pd.read_csv(\"correlation/correlation_TO.csv\")\n",
    "correlation_A = pd.read_csv(\"correlation/correlation_A.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = correlation_TO[\"Y_Quality\"]\n",
    "Q = np.abs(Q)\n",
    "correlation_TO[\"Y_Quality\"] = Q\n",
    "\n",
    "Q = correlation_A[\"Y_Quality\"]\n",
    "Q = np.abs(Q)\n",
    "correlation_A[\"Y_Quality\"] = Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_imp = correlation_TO.sort_values(\"Y_Quality\").iloc[-10:]['Column']\n",
    "A_imp = correlation_A.sort_values(\"Y_Quality\").iloc[-10:]['Column']\n",
    "TO_imp = list(TO_imp)\n",
    "A_imp = list(A_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_median(df , test_df):\n",
    "    # Train에서부터 통계정보 (중앙값) 을 가지고 할당해줌\n",
    "    num_features = df.select_dtypes(exclude=['object']).columns.to_list()\n",
    "    for c in num_features:\n",
    "        m = df[c].median()\n",
    "        df.fillna({c: m}, inplace=True)\n",
    "        test_df.fillna({c: m}, inplace=True)\n",
    "    return df, test_df\n",
    "\n",
    "X_TO, test_TO = fill_median(X_TO, test_TO)\n",
    "X_A, test_A   = fill_median(X_A, test_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(df, test_df):\n",
    "    scaler = StandardScaler()\n",
    "    num_features = df.select_dtypes(exclude=['object']).columns.to_list()[2:]\n",
    "    df[num_features] = scaler.fit_transform(df[num_features])\n",
    "    test_df[num_features] = scaler.transform(test_df[num_features])\n",
    "    return df, test_df\n",
    "\n",
    "X_TO, test_TO = scaling(X_TO, test_TO)\n",
    "X_A, test_A = scaling(X_A, test_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['X_529',\n",
       "  'X_532',\n",
       "  'X_124',\n",
       "  'X_125',\n",
       "  'X_530',\n",
       "  'X_90',\n",
       "  'X_121',\n",
       "  'X_73',\n",
       "  'X_120',\n",
       "  'X_699'],\n",
       " ['X_1012',\n",
       "  'X_1010',\n",
       "  'X_335',\n",
       "  'X_367',\n",
       "  'X_368',\n",
       "  'X_318',\n",
       "  'X_1523',\n",
       "  'X_1524',\n",
       "  'X_1525',\n",
       "  'X_1407'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TO_imp, A_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Simple Cal TO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, product\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import wasserstein_distance as wd\n",
    "from scipy.stats import ks_2samp as ks , energy_distance as ed\n",
    "\n",
    "Additional_cols = X_TO[['PRODUCT_ID', 'Y_Class', 'Y_Quality', 'TIMESTAMP', 'LINE', \"PRODUCT_CODE\"]]\n",
    "test_Additional_cols = test_TO[['PRODUCT_ID', 'TIMESTAMP', 'LINE', \"PRODUCT_CODE\"]]\n",
    "num_features = test_TO.select_dtypes(exclude=['object']).columns.to_list()\n",
    "\n",
    "target = X_TO[\"Y_Class\"]\n",
    "\n",
    "idx2 = X_TO.Y_Class == 2\n",
    "idx1 = X_TO.Y_Class == 1\n",
    "idx0 = X_TO.Y_Class == 0\n",
    "\n",
    "stores=[]\n",
    "newcol = [\"+\" , \"-\" , \"x\"]\n",
    "\n",
    "a = list(combinations(TO_imp , 2))\n",
    "\n",
    "fig , axes = plt.subplots(nrows=len(a) ,ncols=len(newcol),\n",
    "                          figsize=(20,80) )\n",
    "plt.subplots_adjust(left=0.05, bottom=0.01, right=0.99, \n",
    "                    top=0.99, wspace=None, hspace=0.7)\n",
    "\n",
    "ax = axes.flatten()\n",
    "combination = list(map(list, product(a, newcol))) ## 180\n",
    "\n",
    "for idx , col in enumerate(combination) : \n",
    "    one , two = col[0]\n",
    "    cal = col[1]\n",
    "    name = \"{} {} {}\".format(one , cal , two)\n",
    "    if cal == \"+\" :\n",
    "        X_TO[name] = (X_TO.loc[: , one] + X_TO.loc[: , two])\n",
    "        test_TO[name] = (test_TO.loc[:, one] + test_TO.loc[:, two])\n",
    "    elif cal == \"-\" :\n",
    "        X_TO[name] = (X_TO.loc[: , one] - X_TO.loc[: , two])\n",
    "        test_TO[name] = (test_TO.loc[:, one] - test_TO.loc[:, two])\n",
    "    elif cal == \"x\" :\n",
    "        X_TO[name] = (X_TO.loc[: , one] * X_TO.loc[: , two])\n",
    "        test_TO[name] = (test_TO.loc[:, one] * test_TO.loc[:, two])\n",
    "        \n",
    "    #target2 = X_TO.loc[idx2 , [name]].dropna()\n",
    "    #target1 = X_TO.loc[idx1 , [name]].dropna()\n",
    "    #target0 = X_TO.loc[idx0 , [name]].dropna()\n",
    "    \n",
    "    #wdist_1 = wd(np.squeeze(target1) , np.squeeze(target0))\n",
    "    #wdist_2 = wd(np.squeeze(target1) , np.squeeze(target2))\n",
    "    #wdist_3 = wd(np.squeeze(target0) , np.squeeze(target2))\n",
    "    #if wdist_1 > 0.5 and wdist_2 > .5 and wdist_3 > .5 :\n",
    "    stores.append(name)\n",
    "    Additional_cols[name] = X_TO[name]\n",
    "    \"\"\"\n",
    "    sns.distplot(target0 , ax = ax[idx])\n",
    "    sns.distplot(target1 , ax = ax[idx])\n",
    "    sns.distplot(target2 , ax = ax[idx])\n",
    "    \n",
    "    kdist , b = ks(np.squeeze(target1) , np.squeeze(target0))\n",
    "    wdist = wd(np.squeeze(target1) , np.squeeze(target0))\n",
    "    edist = ed(np.squeeze(target1) , np.squeeze(target0))\n",
    "    msg = \"[{}] | ed : {} | ks : {} | wd : {}\".format(name , \n",
    "                                                np.round(edist,3),\n",
    "                                                np.round(kdist,3),\n",
    "                                                np.round(wdist,3),\n",
    "                                            )\n",
    "    ax[idx].set_title(msg , fontsize=  10)\n",
    "    \"\"\"\n",
    "\n",
    "for idx, col in enumerate(stores):\n",
    "    target2 = X_TO.loc[idx2 , [col]].dropna()\n",
    "    target1 = X_TO.loc[idx1 , [col]].dropna()\n",
    "    target0 = X_TO.loc[idx0 , [col]].dropna()\n",
    "    \n",
    "    wdist_1 = wd(np.squeeze(target1) , np.squeeze(target0))\n",
    "    wdist_2 = wd(np.squeeze(target1) , np.squeeze(target2))\n",
    "    wdist_3 = wd(np.squeeze(target0) , np.squeeze(target2))\n",
    "    if wdist_1 > 0.5 and wdist_2 > .5 and wdist_3 > .5 :\n",
    "        sns.distplot(target0 , ax = ax[idx])\n",
    "        sns.distplot(target1 , ax = ax[idx])\n",
    "        sns.distplot(target2 , ax = ax[idx])\n",
    "        \n",
    "        kdist , b = ks(np.squeeze(target1) , np.squeeze(target0))\n",
    "        wdist = wd(np.squeeze(target1) , np.squeeze(target0))\n",
    "        edist = ed(np.squeeze(target1) , np.squeeze(target0))\n",
    "        msg = \"[{}] | ed : {} | ks : {} | wd : {}\".format(name , \n",
    "                                                    np.round(edist,3),\n",
    "                                                    np.round(kdist,3),\n",
    "                                                    np.round(wdist,3),\n",
    "                                                    )\n",
    "        ax[idx].set_title(msg , fontsize=  10)\n",
    "    else:\n",
    "        X_TO.drop(columns=col, inplace=True)\n",
    "        test_TO.drop(columns=col, inplace=True)\n",
    "        \n",
    "        \n",
    "\n",
    "plt.savefig(\"./New.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(349, 606) (243, 604)\n"
     ]
    }
   ],
   "source": [
    "print(X_TO.shape, test_TO.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POLY-Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349, 385)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(4, interaction_only=True ,include_bias=False)\n",
    "important = TO_imp\n",
    "#poly.fit_trans\n",
    "poly_result = poly.fit_transform(X_TO[important])\n",
    "poly_result_test = poly.transform(test_TO[important])\n",
    "\n",
    "cols = [\"poly_{}\".format(i) for i in range(poly_result.shape[1])]\n",
    "cols_test = [\"poly_{}\".format(i) for i in range(poly_result_test.shape[1])]\n",
    "\n",
    "output = pd.DataFrame(poly_result , columns= cols)\n",
    "output_test = pd.DataFrame(poly_result_test, columns=cols_test)\n",
    "output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import wasserstein_distance as wd\n",
    "\n",
    "idx2 = X_TO.Y_Class == 2\n",
    "idx1 = X_TO.Y_Class == 1\n",
    "idx0 = X_TO.Y_Class == 0\n",
    "\n",
    "store = []\n",
    "for idx , col in enumerate(cols) : \n",
    "    target2 = output.loc[idx2 , [col]].dropna()\n",
    "    target1 = output.loc[idx1 , [col]].dropna()\n",
    "    target0 = output.loc[idx0 , [col]].dropna()\n",
    "    \n",
    "    wdist_1 = wd(np.squeeze(target1) , np.squeeze(target0))\n",
    "    wdist_2 = wd(np.squeeze(target1) , np.squeeze(target2))\n",
    "    wdist_3 = wd(np.squeeze(target0) , np.squeeze(target2))\n",
    "    if wdist_1 > .5 and wdist_2 > .5 and wdist_3 > .5:\n",
    "        store.append(col)\n",
    "        Additional_cols[col] = output[col]\n",
    "        X_TO[col] = output[col]\n",
    "        test_TO[col] = output_test[col]\n",
    "        \n",
    "len(store)  ## 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig , axes = plt.subplots(nrows=21 ,ncols=4,\n",
    "                         figsize=(20,42) )\n",
    "plt.subplots_adjust(left=0.05, bottom=0.01, right=0.99, \n",
    "                    top=0.99, wspace=None, hspace=0.7)\n",
    "ax = axes.flatten()\n",
    "for idx , col in enumerate(store): \n",
    "    target2 = output.loc[idx2 , [col]].dropna()\n",
    "    target1 = output.loc[idx1 , [col]].dropna()\n",
    "    target0 = output.loc[idx0 , [col]].dropna()\n",
    "    \n",
    "    kdist , b = ks(np.squeeze(target1) , np.squeeze(target0))\n",
    "    wdist = wd(np.squeeze(target1) , np.squeeze(target0))\n",
    "    edist = ed(np.squeeze(target1) , np.squeeze(target0))\n",
    "    \n",
    "    sns.distplot(target0 , ax = ax[idx])\n",
    "    sns.distplot(target1 , ax = ax[idx])\n",
    "    sns.distplot(target2 , ax = ax[idx])\n",
    "    \n",
    "    msg = \"[{}] | ed : {} | ks : {} | wd : {}\".format(col , \n",
    "                                                np.round(edist,3),\n",
    "                                                np.round(kdist,3),\n",
    "                                                np.round(wdist,3),\n",
    "                                               )\n",
    "    ax[idx].set_title(msg , fontsize=  10)\n",
    "plt.savefig(\"./New2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(349, 689) (243, 687)\n"
     ]
    }
   ],
   "source": [
    "print(X_TO.shape, test_TO.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TO.to_csv(\"split_dataset/train_add_TO.csv\", index=False)\n",
    "test_TO.to_csv(\"split_dataset/test_add_TO.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_X_TO = X_TO.drop(columns=\"Y_Class\")\n",
    "C = corr_X_TO.corr()[[\"Y_Quality\"]]\n",
    "C = C.iloc[1:]\n",
    "C = C.sort_values(\"Y_Quality\")\n",
    "C.to_csv(\"correlation/correlation_add_TO.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Cal A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, product\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import wasserstein_distance as wd\n",
    "from scipy.stats import ks_2samp as ks , energy_distance as ed\n",
    "\n",
    "Additional_cols = X_A[['PRODUCT_ID', 'Y_Class', 'Y_Quality', 'TIMESTAMP', 'LINE', \"PRODUCT_CODE\"]]\n",
    "test_Additional_cols = test_A[['PRODUCT_ID', 'TIMESTAMP', 'LINE', \"PRODUCT_CODE\"]]\n",
    "num_features = test_A.select_dtypes(exclude=['object']).columns.to_list()\n",
    "\n",
    "target = X_A[\"Y_Class\"]\n",
    "\n",
    "idx2 = X_A.Y_Class == 2\n",
    "idx1 = X_A.Y_Class == 1\n",
    "idx0 = X_A.Y_Class == 0\n",
    "\n",
    "stores=[]\n",
    "newcol = [\"+\" , \"-\" , \"x\"]\n",
    "\n",
    "a = list(combinations(A_imp , 2))\n",
    "\n",
    "fig , axes = plt.subplots(nrows=len(a) ,ncols=len(newcol),\n",
    "                          figsize=(20,80) )\n",
    "plt.subplots_adjust(left=0.05, bottom=0.01, right=0.99, \n",
    "                    top=0.99, wspace=None, hspace=0.7)\n",
    "\n",
    "ax = axes.flatten()\n",
    "combination = list(map(list, product(a, newcol))) ## 180\n",
    "\n",
    "for idx , col in enumerate(combination) : \n",
    "    one , two = col[0]\n",
    "    cal = col[1]\n",
    "    name = \"{} {} {}\".format(one , cal , two)\n",
    "    if cal == \"+\" :\n",
    "        X_A[name] = (X_A.loc[: , one] + X_A.loc[: , two])\n",
    "        test_A[name] = (test_A.loc[:, one] + test_A.loc[:, two])\n",
    "    elif cal == \"-\" :\n",
    "        X_A[name] = (X_A.loc[: , one] - X_A.loc[: , two])\n",
    "        test_A[name] = (test_A.loc[:, one] - test_A.loc[:, two])\n",
    "    elif cal == \"x\" :\n",
    "        X_A[name] = (X_A.loc[: , one] * X_A.loc[: , two])\n",
    "        test_A[name] = (test_A.loc[:, one] * test_A.loc[:, two])\n",
    "  \n",
    "    stores.append(name)\n",
    "    Additional_cols[name] = X_A[name]\n",
    "\n",
    "for idx, col in enumerate(stores):\n",
    "    target2 = X_A.loc[idx2 , [col]].dropna()\n",
    "    target1 = X_A.loc[idx1 , [col]].dropna()\n",
    "    target0 = X_A.loc[idx0 , [col]].dropna()\n",
    "    \n",
    "    wdist_1 = wd(np.squeeze(target1) , np.squeeze(target0))\n",
    "    wdist_2 = wd(np.squeeze(target1) , np.squeeze(target2))\n",
    "    wdist_3 = wd(np.squeeze(target0) , np.squeeze(target2))\n",
    "    if wdist_1 > 0.5 and wdist_2 > .5 and wdist_3 > .5 :\n",
    "        sns.distplot(target0 , ax = ax[idx])\n",
    "        sns.distplot(target1 , ax = ax[idx])\n",
    "        sns.distplot(target2 , ax = ax[idx])\n",
    "        \n",
    "        kdist , b = ks(np.squeeze(target1) , np.squeeze(target0))\n",
    "        wdist = wd(np.squeeze(target1) , np.squeeze(target0))\n",
    "        edist = ed(np.squeeze(target1) , np.squeeze(target0))\n",
    "        msg = \"[{}] | ed : {} | ks : {} | wd : {}\".format(name , \n",
    "                                                    np.round(edist,3),\n",
    "                                                    np.round(kdist,3),\n",
    "                                                    np.round(wdist,3),\n",
    "                                                    )\n",
    "        ax[idx].set_title(msg , fontsize=  10)\n",
    "    else:\n",
    "        X_A.drop(columns=col, inplace=True)\n",
    "        test_A.drop(columns=col, inplace=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249, 385)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(4, interaction_only=True ,include_bias=False)\n",
    "important = A_imp\n",
    "#poly.fit_trans\n",
    "poly_result = poly.fit_transform(X_A[important])\n",
    "poly_result_test = poly.transform(test_A[important])\n",
    "\n",
    "cols = [\"poly_{}\".format(i) for i in range(poly_result.shape[1])]\n",
    "cols_test = [\"poly_{}\".format(i) for i in range(poly_result_test.shape[1])]\n",
    "\n",
    "output = pd.DataFrame(poly_result , columns= cols)\n",
    "output_test = pd.DataFrame(poly_result_test, columns=cols_test)\n",
    "output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import wasserstein_distance as wd\n",
    "\n",
    "idx2 = X_A.Y_Class == 2\n",
    "idx1 = X_A.Y_Class == 1\n",
    "idx0 = X_A.Y_Class == 0\n",
    "\n",
    "store = []\n",
    "for idx , col in enumerate(cols) : \n",
    "    target2 = output.loc[idx2 , [col]].dropna()\n",
    "    target1 = output.loc[idx1 , [col]].dropna()\n",
    "    target0 = output.loc[idx0 , [col]].dropna()\n",
    "    \n",
    "    wdist_1 = wd(np.squeeze(target1) , np.squeeze(target0))\n",
    "    wdist_2 = wd(np.squeeze(target1) , np.squeeze(target2))\n",
    "    wdist_3 = wd(np.squeeze(target0) , np.squeeze(target2))\n",
    "    if wdist_1 > .5 and wdist_2 > .5 and wdist_3 > .5:\n",
    "        store.append(col)\n",
    "        Additional_cols[col] = output[col]\n",
    "        X_A[col] = output[col]\n",
    "        test_A[col] = output_test[col]\n",
    "        \n",
    "len(store)  ## 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig , axes = plt.subplots(nrows=21 ,ncols=4,\n",
    "                         figsize=(20,42) )\n",
    "plt.subplots_adjust(left=0.05, bottom=0.01, right=0.99, \n",
    "                    top=0.99, wspace=None, hspace=0.7)\n",
    "ax = axes.flatten()\n",
    "for idx , col in enumerate(store): \n",
    "    target2 = output.loc[idx2 , [col]].dropna()\n",
    "    target1 = output.loc[idx1 , [col]].dropna()\n",
    "    target0 = output.loc[idx0 , [col]].dropna()\n",
    "    \n",
    "    kdist , b = ks(np.squeeze(target1) , np.squeeze(target0))\n",
    "    wdist = wd(np.squeeze(target1) , np.squeeze(target0))\n",
    "    edist = ed(np.squeeze(target1) , np.squeeze(target0))\n",
    "    \n",
    "    sns.distplot(target0 , ax = ax[idx])\n",
    "    sns.distplot(target1 , ax = ax[idx])\n",
    "    sns.distplot(target2 , ax = ax[idx])\n",
    "    \n",
    "    msg = \"[{}] | ed : {} | ks : {} | wd : {}\".format(col , \n",
    "                                                np.round(edist,3),\n",
    "                                                np.round(kdist,3),\n",
    "                                                np.round(wdist,3),\n",
    "                                               )\n",
    "    ax[idx].set_title(msg , fontsize=  10)\n",
    "plt.savefig(\"./New2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 1906) (67, 1904)\n"
     ]
    }
   ],
   "source": [
    "print(X_A.shape, test_A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1059305/3351170623.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"split_dataset/train_add_A.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"split_dataset/test_add_A.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_A' is not defined"
     ]
    }
   ],
   "source": [
    "X_A.to_csv(\"split_dataset/train_add_A.csv\", index=False)\n",
    "test_A.to_csv(\"split_dataset/test_add_A.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_X_A = X_A.drop(columns=\"Y_Class\")\n",
    "C = corr_X_A.corr()[[\"Y_Quality\"]]\n",
    "C = C.iloc[1:]\n",
    "C = C.sort_values(\"Y_Quality\")\n",
    "C.to_csv(\"correlation/correlation_add_A.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_TO = pd.read_csv(\"split_dataset/test_add_TO.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in test_TO:\n",
    "    if 'poly' in col:\n",
    "        test_TO.rename(columns={col: \"TO_\"+col}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train = pd.concat([X_TO, X_A])\n",
    "total_test  = pd.concat([test_TO, test_A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train.sort_values(\"PRODUCT_ID\", inplace=True)\n",
    "total_test.sort_values(\"PRODUCT_ID\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train.to_csv(\"train_add.csv\", index=False)\n",
    "total_test.to_csv(\"test_add.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "best = pd.read_csv(\"best.csv\")[\"Y_Class\"]\n",
    "cur = pd.read_csv(\"submission.csv\")[\"Y_Class\"]\n",
    "PCA = pd.read_csv(\"submission_PCA.csv\")[\"Y_Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.83870967741936\n"
     ]
    }
   ],
   "source": [
    "match = 0\n",
    "for i in range(310):\n",
    "    if best.iloc[i] == cur.iloc[i]:\n",
    "        match+= 1\n",
    "print((match / 310) * 100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.2258064516129\n"
     ]
    }
   ],
   "source": [
    "match = 0\n",
    "for i in range(310):\n",
    "    if best.iloc[i] == PCA.iloc[i]:\n",
    "        match+= 1\n",
    "print((match / 310) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    253\n",
       "0     32\n",
       "2     25\n",
       "Name: Y_Class, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    244\n",
       "0     40\n",
       "2     26\n",
       "Name: Y_Class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    251\n",
       "0     38\n",
       "2     21\n",
       "Name: Y_Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_31    239\n",
       "A_31     67\n",
       "O_31      4\n",
       "Name: PRODUCT_CODE, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.read_csv(\"dataset/test.csv\")\n",
    "tmp['PRODUCT_CODE'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2e4a47e36f0811c316f759d1a92830bb55dbd78977c69f453a1e4981941b515"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
