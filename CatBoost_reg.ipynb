{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import warnings\n",
    "\n",
    "# hyperparameter\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "#Modeling\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier, VotingClassifier,RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, RidgeClassifierCV\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error, f1_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "SEED = 25\n",
    "seed_everything(SEED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset/train.csv')\n",
    "test = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "train.drop(columns=[\"PRODUCT_ID\", \"TIMESTAMP\", 'LINE', 'PRODUCT_CODE'], inplace=True)\n",
    "test.drop(columns=[\"PRODUCT_ID\", \"TIMESTAMP\", 'LINE', 'PRODUCT_CODE'], inplace=True)\n",
    "y_class = train['Y_Class']\n",
    "y = train['Y_Quality']\n",
    "\n",
    "num_features = test.select_dtypes(exclude=['object']).columns.to_list()\n",
    "\n",
    "\n",
    "#for col in num_features:\n",
    "#    train[col] = train[col].fillna(train[col].median())\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#scaler = QuantileTransformer()\n",
    "train[num_features] = scaler.fit_transform(train[num_features])\n",
    "test[num_features] = scaler.transform(test[num_features])\n",
    "\n",
    "X = train.drop(columns=['Y_Class', 'Y_Quality'])\n",
    "X_test = test\n",
    "\n",
    "#from math import *\n",
    "corr = pd.read_csv('correlation/correlation.csv')\n",
    "# Y_Quality 제거\n",
    "corr = corr.iloc[:-1,:]\n",
    "important = list(corr[abs(corr['correlation'])>=0.1]['feature'])\n",
    "#important\n",
    "X = X[important]\n",
    "X_test = X_test[important]\n",
    "\n",
    "dup = ~X.T.duplicated()\n",
    "X = X.loc[:, dup]\n",
    "X_test = X_test.loc[:, dup]\n",
    "\n",
    "#num_features = X_test.select_dtypes(exclude=['object']).columns.to_list()\n",
    "#scaler = StandardScaler()\n",
    "#X[num_features] = scaler.fit_transform(X[num_features])\n",
    "#X_test[num_features] = scaler.transform(X_test[num_features])\n",
    "imputer = KNNImputer()\n",
    "X = imputer.fit_transform(X)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0073863\ttest: 0.0071955\tbest: 0.0071955 (0)\ttotal: 87.5ms\tremaining: 7m 17s\n",
      "200:\tlearn: 0.0043105\ttest: 0.0048082\tbest: 0.0048082 (200)\ttotal: 6.29s\tremaining: 2m 30s\n",
      "400:\tlearn: 0.0030564\ttest: 0.0041107\tbest: 0.0041107 (400)\ttotal: 12.7s\tremaining: 2m 25s\n",
      "600:\tlearn: 0.0020714\ttest: 0.0038218\tbest: 0.0038218 (600)\ttotal: 19s\tremaining: 2m 19s\n",
      "800:\tlearn: 0.0014223\ttest: 0.0037439\tbest: 0.0037433 (799)\ttotal: 25.4s\tremaining: 2m 13s\n",
      "1000:\tlearn: 0.0009844\ttest: 0.0037055\tbest: 0.0037041 (997)\ttotal: 31.7s\tremaining: 2m 6s\n",
      "1200:\tlearn: 0.0006877\ttest: 0.0036883\tbest: 0.0036880 (1198)\ttotal: 38.1s\tremaining: 2m\n",
      "1400:\tlearn: 0.0004791\ttest: 0.0036795\tbest: 0.0036779 (1300)\ttotal: 44.5s\tremaining: 1m 54s\n",
      "1600:\tlearn: 0.0003343\ttest: 0.0036797\tbest: 0.0036778 (1411)\ttotal: 50.9s\tremaining: 1m 47s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.003677791226\n",
      "bestIteration = 1411\n",
      "\n",
      "Shrink model to first 1412 iterations.\n",
      "========== fold 1 ==========\n",
      "CatBoostRegressor model nrmse : 0.0037\n",
      "LGBMRegressor model nrmse : 0.0054\n",
      "XGBRegressor model nrmse : 0.0038\n",
      "CAT 코드 실행 시간:         51s\n",
      "LGB 코드 실행 시간:          1s\n",
      "XGB 코드 실행 시간:          6s\n",
      "average model nrmse : 0.0039\n",
      "0:\tlearn: 0.0074940\ttest: 0.0060064\tbest: 0.0060064 (0)\ttotal: 32.7ms\tremaining: 2m 43s\n",
      "200:\tlearn: 0.0042230\ttest: 0.0050801\tbest: 0.0050787 (198)\ttotal: 6.33s\tremaining: 2m 31s\n",
      "400:\tlearn: 0.0029910\ttest: 0.0046266\tbest: 0.0046266 (400)\ttotal: 12.8s\tremaining: 2m 26s\n",
      "600:\tlearn: 0.0020321\ttest: 0.0044781\tbest: 0.0044753 (597)\ttotal: 19.4s\tremaining: 2m 22s\n",
      "800:\tlearn: 0.0013927\ttest: 0.0044249\tbest: 0.0044170 (763)\ttotal: 26s\tremaining: 2m 16s\n",
      "1000:\tlearn: 0.0009563\ttest: 0.0044178\tbest: 0.0044141 (837)\ttotal: 32.6s\tremaining: 2m 10s\n",
      "1200:\tlearn: 0.0006578\ttest: 0.0044141\tbest: 0.0044055 (1038)\ttotal: 39.2s\tremaining: 2m 4s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.004405519487\n",
      "bestIteration = 1038\n",
      "\n",
      "Shrink model to first 1039 iterations.\n",
      "========== fold 2 ==========\n",
      "CatBoostRegressor model nrmse : 0.0044\n",
      "LGBMRegressor model nrmse : 0.0055\n",
      "XGBRegressor model nrmse : 0.0042\n",
      "CAT 코드 실행 시간:         40s\n",
      "LGB 코드 실행 시간:          1s\n",
      "XGB 코드 실행 시간:          6s\n",
      "average model nrmse : 0.0045\n",
      "0:\tlearn: 0.0073595\ttest: 0.0072858\tbest: 0.0072858 (0)\ttotal: 32.6ms\tremaining: 2m 42s\n",
      "200:\tlearn: 0.0041591\ttest: 0.0058531\tbest: 0.0058531 (200)\ttotal: 6.33s\tremaining: 2m 31s\n",
      "400:\tlearn: 0.0029199\ttest: 0.0054540\tbest: 0.0054540 (400)\ttotal: 12.6s\tremaining: 2m 24s\n",
      "600:\tlearn: 0.0019280\ttest: 0.0053092\tbest: 0.0053051 (592)\ttotal: 19s\tremaining: 2m 18s\n",
      "800:\tlearn: 0.0013054\ttest: 0.0052465\tbest: 0.0052464 (799)\ttotal: 25.4s\tremaining: 2m 12s\n",
      "1000:\tlearn: 0.0008984\ttest: 0.0052210\tbest: 0.0052210 (1000)\ttotal: 31.7s\tremaining: 2m 6s\n",
      "1200:\tlearn: 0.0006173\ttest: 0.0052102\tbest: 0.0052102 (1200)\ttotal: 38.1s\tremaining: 2m\n",
      "1400:\tlearn: 0.0004294\ttest: 0.0051976\tbest: 0.0051974 (1388)\ttotal: 44.5s\tremaining: 1m 54s\n",
      "1600:\tlearn: 0.0002987\ttest: 0.0051969\tbest: 0.0051969 (1600)\ttotal: 50.9s\tremaining: 1m 48s\n",
      "1800:\tlearn: 0.0002084\ttest: 0.0051943\tbest: 0.0051934 (1731)\ttotal: 57.3s\tremaining: 1m 41s\n",
      "2000:\tlearn: 0.0001466\ttest: 0.0051922\tbest: 0.0051919 (1990)\ttotal: 1m 3s\tremaining: 1m 35s\n",
      "2200:\tlearn: 0.0001034\ttest: 0.0051920\tbest: 0.0051914 (2082)\ttotal: 1m 10s\tremaining: 1m 29s\n",
      "2400:\tlearn: 0.0000727\ttest: 0.0051915\tbest: 0.0051911 (2321)\ttotal: 1m 16s\tremaining: 1m 22s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.005191099546\n",
      "bestIteration = 2321\n",
      "\n",
      "Shrink model to first 2322 iterations.\n",
      "========== fold 3 ==========\n",
      "CatBoostRegressor model nrmse : 0.0052\n",
      "LGBMRegressor model nrmse : 0.0055\n",
      "XGBRegressor model nrmse : 0.0050\n",
      "CAT 코드 실행 시간:         81s\n",
      "LGB 코드 실행 시간:          1s\n",
      "XGB 코드 실행 시간:          6s\n",
      "average model nrmse : 0.0050\n",
      "0:\tlearn: 0.0070909\ttest: 0.0094468\tbest: 0.0094468 (0)\ttotal: 33ms\tremaining: 2m 44s\n",
      "200:\tlearn: 0.0040649\ttest: 0.0078018\tbest: 0.0078018 (200)\ttotal: 6.31s\tremaining: 2m 30s\n",
      "400:\tlearn: 0.0029291\ttest: 0.0072852\tbest: 0.0072851 (399)\ttotal: 12.6s\tremaining: 2m 24s\n",
      "600:\tlearn: 0.0019528\ttest: 0.0070648\tbest: 0.0070645 (599)\ttotal: 19s\tremaining: 2m 19s\n",
      "800:\tlearn: 0.0013239\ttest: 0.0069984\tbest: 0.0069957 (795)\ttotal: 25.4s\tremaining: 2m 13s\n",
      "1000:\tlearn: 0.0009043\ttest: 0.0069531\tbest: 0.0069510 (994)\ttotal: 31.8s\tremaining: 2m 6s\n",
      "1200:\tlearn: 0.0006239\ttest: 0.0069387\tbest: 0.0069367 (1156)\ttotal: 38.1s\tremaining: 2m\n",
      "1400:\tlearn: 0.0004328\ttest: 0.0069298\tbest: 0.0069283 (1370)\ttotal: 44.5s\tremaining: 1m 54s\n",
      "1600:\tlearn: 0.0002970\ttest: 0.0069259\tbest: 0.0069248 (1553)\ttotal: 50.9s\tremaining: 1m 47s\n",
      "1800:\tlearn: 0.0002060\ttest: 0.0069219\tbest: 0.0069216 (1759)\ttotal: 57.2s\tremaining: 1m 41s\n",
      "2000:\tlearn: 0.0001446\ttest: 0.0069186\tbest: 0.0069186 (2000)\ttotal: 1m 3s\tremaining: 1m 35s\n",
      "2200:\tlearn: 0.0001012\ttest: 0.0069171\tbest: 0.0069170 (2197)\ttotal: 1m 9s\tremaining: 1m 28s\n",
      "2400:\tlearn: 0.0000714\ttest: 0.0069159\tbest: 0.0069157 (2384)\ttotal: 1m 16s\tremaining: 1m 22s\n",
      "2600:\tlearn: 0.0000506\ttest: 0.0069154\tbest: 0.0069154 (2555)\ttotal: 1m 22s\tremaining: 1m 16s\n",
      "2800:\tlearn: 0.0000360\ttest: 0.0069145\tbest: 0.0069145 (2788)\ttotal: 1m 29s\tremaining: 1m 9s\n",
      "3000:\tlearn: 0.0000256\ttest: 0.0069143\tbest: 0.0069143 (2996)\ttotal: 1m 35s\tremaining: 1m 3s\n",
      "3200:\tlearn: 0.0000184\ttest: 0.0069140\tbest: 0.0069140 (3104)\ttotal: 1m 41s\tremaining: 57.2s\n",
      "3400:\tlearn: 0.0000131\ttest: 0.0069138\tbest: 0.0069138 (3363)\ttotal: 1m 48s\tremaining: 50.9s\n",
      "3600:\tlearn: 0.0000094\ttest: 0.0069137\tbest: 0.0069137 (3596)\ttotal: 1m 54s\tremaining: 44.5s\n",
      "3800:\tlearn: 0.0000067\ttest: 0.0069137\tbest: 0.0069136 (3762)\ttotal: 2m\tremaining: 38.2s\n",
      "4000:\tlearn: 0.0000048\ttest: 0.0069137\tbest: 0.0069136 (3957)\ttotal: 2m 7s\tremaining: 31.8s\n",
      "4200:\tlearn: 0.0000034\ttest: 0.0069136\tbest: 0.0069136 (4190)\ttotal: 2m 13s\tremaining: 25.4s\n",
      "4400:\tlearn: 0.0000024\ttest: 0.0069136\tbest: 0.0069136 (4343)\ttotal: 2m 20s\tremaining: 19.1s\n",
      "4600:\tlearn: 0.0000017\ttest: 0.0069136\tbest: 0.0069136 (4599)\ttotal: 2m 26s\tremaining: 12.7s\n",
      "4800:\tlearn: 0.0000013\ttest: 0.0069136\tbest: 0.0069135 (4675)\ttotal: 2m 32s\tremaining: 6.34s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.006913540979\n",
      "bestIteration = 4675\n",
      "\n",
      "Shrink model to first 4676 iterations.\n",
      "========== fold 4 ==========\n",
      "CatBoostRegressor model nrmse : 0.0069\n",
      "LGBMRegressor model nrmse : 0.0086\n",
      "XGBRegressor model nrmse : 0.0056\n",
      "CAT 코드 실행 시간:        156s\n",
      "LGB 코드 실행 시간:          1s\n",
      "XGB 코드 실행 시간:          6s\n",
      "average model nrmse : 0.0068\n",
      "0:\tlearn: 0.0075274\ttest: 0.0056486\tbest: 0.0056486 (0)\ttotal: 32.4ms\tremaining: 2m 41s\n",
      "200:\tlearn: 0.0042143\ttest: 0.0045314\tbest: 0.0045314 (200)\ttotal: 6.39s\tremaining: 2m 32s\n",
      "400:\tlearn: 0.0029153\ttest: 0.0042149\tbest: 0.0042142 (398)\ttotal: 12.8s\tremaining: 2m 26s\n",
      "600:\tlearn: 0.0019499\ttest: 0.0040461\tbest: 0.0040451 (599)\ttotal: 19.2s\tremaining: 2m 20s\n",
      "800:\tlearn: 0.0013156\ttest: 0.0039882\tbest: 0.0039872 (798)\ttotal: 25.7s\tremaining: 2m 14s\n",
      "1000:\tlearn: 0.0009089\ttest: 0.0039522\tbest: 0.0039519 (998)\ttotal: 32.1s\tremaining: 2m 8s\n",
      "1200:\tlearn: 0.0006239\ttest: 0.0039317\tbest: 0.0039312 (1178)\ttotal: 38.6s\tremaining: 2m 2s\n",
      "1400:\tlearn: 0.0004380\ttest: 0.0039252\tbest: 0.0039250 (1397)\ttotal: 45s\tremaining: 1m 55s\n",
      "1600:\tlearn: 0.0003032\ttest: 0.0039179\tbest: 0.0039177 (1599)\ttotal: 51.5s\tremaining: 1m 49s\n",
      "1800:\tlearn: 0.0002100\ttest: 0.0039132\tbest: 0.0039127 (1790)\ttotal: 57.9s\tremaining: 1m 42s\n",
      "2000:\tlearn: 0.0001464\ttest: 0.0039117\tbest: 0.0039115 (1906)\ttotal: 1m 4s\tremaining: 1m 36s\n",
      "2200:\tlearn: 0.0001031\ttest: 0.0039092\tbest: 0.0039089 (2187)\ttotal: 1m 10s\tremaining: 1m 30s\n",
      "2400:\tlearn: 0.0000720\ttest: 0.0039091\tbest: 0.0039087 (2244)\ttotal: 1m 17s\tremaining: 1m 23s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.003908740263\n",
      "bestIteration = 2244\n",
      "\n",
      "Shrink model to first 2245 iterations.\n",
      "========== fold 5 ==========\n",
      "CatBoostRegressor model nrmse : 0.0039\n",
      "LGBMRegressor model nrmse : 0.0046\n",
      "XGBRegressor model nrmse : 0.0038\n",
      "CAT 코드 실행 시간:         79s\n",
      "LGB 코드 실행 시간:          1s\n",
      "XGB 코드 실행 시간:          6s\n",
      "average model nrmse : 0.0039\n",
      "0:\tlearn: 0.0073346\ttest: 0.0076088\tbest: 0.0076088 (0)\ttotal: 30.6ms\tremaining: 2m 33s\n",
      "200:\tlearn: 0.0042503\ttest: 0.0060219\tbest: 0.0060219 (200)\ttotal: 6.03s\tremaining: 2m 23s\n",
      "400:\tlearn: 0.0030136\ttest: 0.0054455\tbest: 0.0054449 (399)\ttotal: 12.1s\tremaining: 2m 18s\n",
      "600:\tlearn: 0.0020298\ttest: 0.0051583\tbest: 0.0051583 (600)\ttotal: 18.3s\tremaining: 2m 13s\n",
      "800:\tlearn: 0.0013918\ttest: 0.0050706\tbest: 0.0050706 (800)\ttotal: 24.4s\tremaining: 2m 8s\n",
      "1000:\tlearn: 0.0009554\ttest: 0.0050360\tbest: 0.0050358 (999)\ttotal: 30.6s\tremaining: 2m 2s\n",
      "1200:\tlearn: 0.0006614\ttest: 0.0050191\tbest: 0.0050167 (1187)\ttotal: 36.7s\tremaining: 1m 56s\n",
      "1400:\tlearn: 0.0004591\ttest: 0.0050142\tbest: 0.0050136 (1392)\ttotal: 42.9s\tremaining: 1m 50s\n",
      "1600:\tlearn: 0.0003171\ttest: 0.0050091\tbest: 0.0050079 (1585)\ttotal: 49.1s\tremaining: 1m 44s\n",
      "1800:\tlearn: 0.0002217\ttest: 0.0050075\tbest: 0.0050069 (1784)\ttotal: 55.2s\tremaining: 1m 38s\n",
      "2000:\tlearn: 0.0001567\ttest: 0.0050063\tbest: 0.0050051 (1891)\ttotal: 1m 1s\tremaining: 1m 32s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.005005142429\n",
      "bestIteration = 1891\n",
      "\n",
      "Shrink model to first 1892 iterations.\n",
      "========== fold 6 ==========\n",
      "CatBoostRegressor model nrmse : 0.0050\n",
      "LGBMRegressor model nrmse : 0.0062\n",
      "XGBRegressor model nrmse : 0.0041\n",
      "CAT 코드 실행 시간:         64s\n",
      "LGB 코드 실행 시간:          1s\n",
      "XGB 코드 실행 시간:          6s\n",
      "average model nrmse : 0.0048\n",
      "0:\tlearn: 0.0074636\ttest: 0.0064325\tbest: 0.0064325 (0)\ttotal: 32.6ms\tremaining: 2m 42s\n",
      "200:\tlearn: 0.0042301\ttest: 0.0049099\tbest: 0.0049099 (200)\ttotal: 6.2s\tremaining: 2m 28s\n",
      "400:\tlearn: 0.0029358\ttest: 0.0045301\tbest: 0.0045292 (396)\ttotal: 12.4s\tremaining: 2m 22s\n",
      "600:\tlearn: 0.0019426\ttest: 0.0044034\tbest: 0.0044034 (600)\ttotal: 18.7s\tremaining: 2m 16s\n",
      "800:\tlearn: 0.0013365\ttest: 0.0043397\tbest: 0.0043389 (799)\ttotal: 25s\tremaining: 2m 11s\n",
      "1000:\tlearn: 0.0009105\ttest: 0.0043073\tbest: 0.0043071 (999)\ttotal: 31.3s\tremaining: 2m 5s\n",
      "1200:\tlearn: 0.0006285\ttest: 0.0042972\tbest: 0.0042958 (1192)\ttotal: 37.6s\tremaining: 1m 58s\n",
      "1400:\tlearn: 0.0004353\ttest: 0.0042945\tbest: 0.0042926 (1348)\ttotal: 43.9s\tremaining: 1m 52s\n",
      "1600:\tlearn: 0.0003055\ttest: 0.0042884\tbest: 0.0042878 (1573)\ttotal: 50.2s\tremaining: 1m 46s\n",
      "1800:\tlearn: 0.0002101\ttest: 0.0042872\tbest: 0.0042865 (1771)\ttotal: 56.5s\tremaining: 1m 40s\n",
      "2000:\tlearn: 0.0001452\ttest: 0.0042832\tbest: 0.0042828 (1975)\ttotal: 1m 2s\tremaining: 1m 34s\n",
      "2200:\tlearn: 0.0001004\ttest: 0.0042812\tbest: 0.0042812 (2200)\ttotal: 1m 9s\tremaining: 1m 27s\n",
      "2400:\tlearn: 0.0000693\ttest: 0.0042808\tbest: 0.0042806 (2362)\ttotal: 1m 15s\tremaining: 1m 21s\n",
      "2600:\tlearn: 0.0000482\ttest: 0.0042800\tbest: 0.0042799 (2593)\ttotal: 1m 21s\tremaining: 1m 15s\n",
      "2800:\tlearn: 0.0000338\ttest: 0.0042799\tbest: 0.0042799 (2796)\ttotal: 1m 28s\tremaining: 1m 9s\n",
      "3000:\tlearn: 0.0000239\ttest: 0.0042798\tbest: 0.0042797 (2845)\ttotal: 1m 34s\tremaining: 1m 2s\n",
      "3200:\tlearn: 0.0000169\ttest: 0.0042796\tbest: 0.0042796 (3195)\ttotal: 1m 40s\tremaining: 56.5s\n",
      "3400:\tlearn: 0.0000119\ttest: 0.0042796\tbest: 0.0042796 (3384)\ttotal: 1m 46s\tremaining: 50.2s\n",
      "3600:\tlearn: 0.0000084\ttest: 0.0042795\tbest: 0.0042795 (3586)\ttotal: 1m 53s\tremaining: 44s\n",
      "3800:\tlearn: 0.0000059\ttest: 0.0042794\tbest: 0.0042794 (3800)\ttotal: 1m 59s\tremaining: 37.7s\n",
      "4000:\tlearn: 0.0000041\ttest: 0.0042794\tbest: 0.0042794 (4000)\ttotal: 2m 5s\tremaining: 31.4s\n",
      "4200:\tlearn: 0.0000029\ttest: 0.0042794\tbest: 0.0042794 (4130)\ttotal: 2m 12s\tremaining: 25.1s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.004279361994\n",
      "bestIteration = 4130\n",
      "\n",
      "Shrink model to first 4131 iterations.\n",
      "========== fold 7 ==========\n",
      "CatBoostRegressor model nrmse : 0.0043\n",
      "LGBMRegressor model nrmse : 0.0049\n",
      "XGBRegressor model nrmse : 0.0039\n",
      "CAT 코드 실행 시간:        137s\n",
      "LGB 코드 실행 시간:          1s\n",
      "XGB 코드 실행 시간:          6s\n",
      "average model nrmse : 0.0041\n",
      "0:\tlearn: 0.0071908\ttest: 0.0087659\tbest: 0.0087659 (0)\ttotal: 31.5ms\tremaining: 2m 37s\n",
      "200:\tlearn: 0.0042725\ttest: 0.0065163\tbest: 0.0065163 (200)\ttotal: 6.24s\tremaining: 2m 29s\n",
      "400:\tlearn: 0.0030331\ttest: 0.0056261\tbest: 0.0056261 (400)\ttotal: 12.5s\tremaining: 2m 23s\n",
      "600:\tlearn: 0.0020392\ttest: 0.0052697\tbest: 0.0052684 (599)\ttotal: 18.9s\tremaining: 2m 18s\n",
      "800:\tlearn: 0.0014142\ttest: 0.0051816\tbest: 0.0051807 (799)\ttotal: 25.2s\tremaining: 2m 12s\n",
      "1000:\tlearn: 0.0009753\ttest: 0.0051315\tbest: 0.0051299 (995)\ttotal: 31.5s\tremaining: 2m 5s\n",
      "1200:\tlearn: 0.0006704\ttest: 0.0051094\tbest: 0.0051087 (1193)\ttotal: 37.8s\tremaining: 1m 59s\n",
      "1400:\tlearn: 0.0004627\ttest: 0.0050964\tbest: 0.0050964 (1400)\ttotal: 44.1s\tremaining: 1m 53s\n",
      "1600:\tlearn: 0.0003225\ttest: 0.0050880\tbest: 0.0050872 (1575)\ttotal: 50.5s\tremaining: 1m 47s\n",
      "1800:\tlearn: 0.0002256\ttest: 0.0050849\tbest: 0.0050849 (1800)\ttotal: 56.8s\tremaining: 1m 40s\n",
      "2000:\tlearn: 0.0001568\ttest: 0.0050833\tbest: 0.0050831 (1991)\ttotal: 1m 3s\tremaining: 1m 34s\n",
      "2200:\tlearn: 0.0001107\ttest: 0.0050808\tbest: 0.0050806 (2192)\ttotal: 1m 9s\tremaining: 1m 28s\n",
      "2400:\tlearn: 0.0000775\ttest: 0.0050798\tbest: 0.0050796 (2301)\ttotal: 1m 15s\tremaining: 1m 21s\n",
      "2600:\tlearn: 0.0000544\ttest: 0.0050790\tbest: 0.0050789 (2586)\ttotal: 1m 22s\tremaining: 1m 15s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.005078861806\n",
      "bestIteration = 2586\n",
      "\n",
      "Shrink model to first 2587 iterations.\n",
      "========== fold 8 ==========\n",
      "CatBoostRegressor model nrmse : 0.0051\n",
      "LGBMRegressor model nrmse : 0.0071\n",
      "XGBRegressor model nrmse : 0.0041\n",
      "CAT 코드 실행 시간:         88s\n",
      "LGB 코드 실행 시간:          1s\n",
      "XGB 코드 실행 시간:          6s\n",
      "average model nrmse : 0.0051\n",
      "0:\tlearn: 0.0074743\ttest: 0.0062687\tbest: 0.0062687 (0)\ttotal: 31.2ms\tremaining: 2m 35s\n",
      "200:\tlearn: 0.0042245\ttest: 0.0043305\tbest: 0.0043305 (200)\ttotal: 6.11s\tremaining: 2m 25s\n",
      "400:\tlearn: 0.0030412\ttest: 0.0040403\tbest: 0.0040382 (394)\ttotal: 12.2s\tremaining: 2m 19s\n",
      "600:\tlearn: 0.0020124\ttest: 0.0039435\tbest: 0.0039413 (596)\ttotal: 18.4s\tremaining: 2m 15s\n",
      "800:\tlearn: 0.0013681\ttest: 0.0039122\tbest: 0.0039114 (798)\ttotal: 24.7s\tremaining: 2m 9s\n",
      "1000:\tlearn: 0.0009403\ttest: 0.0038931\tbest: 0.0038931 (1000)\ttotal: 30.9s\tremaining: 2m 3s\n",
      "1200:\tlearn: 0.0006472\ttest: 0.0038848\tbest: 0.0038843 (1183)\ttotal: 37.1s\tremaining: 1m 57s\n",
      "1400:\tlearn: 0.0004538\ttest: 0.0038829\tbest: 0.0038823 (1395)\ttotal: 43.4s\tremaining: 1m 51s\n",
      "1600:\tlearn: 0.0003166\ttest: 0.0038841\tbest: 0.0038823 (1554)\ttotal: 49.6s\tremaining: 1m 45s\n",
      "1800:\tlearn: 0.0002221\ttest: 0.0038802\tbest: 0.0038799 (1797)\ttotal: 55.8s\tremaining: 1m 39s\n",
      "2000:\tlearn: 0.0001565\ttest: 0.0038802\tbest: 0.0038798 (1833)\ttotal: 1m 2s\tremaining: 1m 33s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.003879786355\n",
      "bestIteration = 1833\n",
      "\n",
      "Shrink model to first 1834 iterations.\n",
      "========== fold 9 ==========\n",
      "CatBoostRegressor model nrmse : 0.0039\n",
      "LGBMRegressor model nrmse : 0.0053\n",
      "XGBRegressor model nrmse : 0.0042\n",
      "CAT 코드 실행 시간:         63s\n",
      "LGB 코드 실행 시간:          1s\n",
      "XGB 코드 실행 시간:          6s\n",
      "average model nrmse : 0.0041\n",
      "0:\tlearn: 0.0072490\ttest: 0.0083223\tbest: 0.0083223 (0)\ttotal: 31.2ms\tremaining: 2m 35s\n",
      "200:\tlearn: 0.0040056\ttest: 0.0069294\tbest: 0.0069294 (200)\ttotal: 6.08s\tremaining: 2m 25s\n",
      "400:\tlearn: 0.0028539\ttest: 0.0062891\tbest: 0.0062891 (399)\ttotal: 12.2s\tremaining: 2m 20s\n",
      "600:\tlearn: 0.0019328\ttest: 0.0060102\tbest: 0.0060102 (600)\ttotal: 18.4s\tremaining: 2m 14s\n",
      "800:\tlearn: 0.0013295\ttest: 0.0059018\tbest: 0.0059018 (800)\ttotal: 24.7s\tremaining: 2m 9s\n",
      "1000:\tlearn: 0.0009128\ttest: 0.0058648\tbest: 0.0058648 (1000)\ttotal: 30.9s\tremaining: 2m 3s\n",
      "1200:\tlearn: 0.0006336\ttest: 0.0058369\tbest: 0.0058369 (1200)\ttotal: 37.2s\tremaining: 1m 57s\n",
      "1400:\tlearn: 0.0004385\ttest: 0.0058238\tbest: 0.0058233 (1398)\ttotal: 43.4s\tremaining: 1m 51s\n",
      "1600:\tlearn: 0.0003015\ttest: 0.0058147\tbest: 0.0058143 (1595)\ttotal: 49.6s\tremaining: 1m 45s\n",
      "1800:\tlearn: 0.0002081\ttest: 0.0058069\tbest: 0.0058068 (1799)\ttotal: 55.8s\tremaining: 1m 39s\n",
      "2000:\tlearn: 0.0001438\ttest: 0.0058058\tbest: 0.0058058 (1987)\ttotal: 1m 2s\tremaining: 1m 32s\n",
      "2200:\tlearn: 0.0001007\ttest: 0.0058047\tbest: 0.0058046 (2197)\ttotal: 1m 8s\tremaining: 1m 26s\n",
      "2400:\tlearn: 0.0000698\ttest: 0.0058032\tbest: 0.0058032 (2395)\ttotal: 1m 14s\tremaining: 1m 20s\n",
      "2600:\tlearn: 0.0000495\ttest: 0.0058026\tbest: 0.0058026 (2585)\ttotal: 1m 20s\tremaining: 1m 14s\n",
      "2800:\tlearn: 0.0000350\ttest: 0.0058021\tbest: 0.0058021 (2792)\ttotal: 1m 26s\tremaining: 1m 8s\n",
      "3000:\tlearn: 0.0000244\ttest: 0.0058023\tbest: 0.0058020 (2859)\ttotal: 1m 33s\tremaining: 1m 2s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.005801955647\n",
      "bestIteration = 2859\n",
      "\n",
      "Shrink model to first 2860 iterations.\n",
      "========== fold 10 ==========\n",
      "CatBoostRegressor model nrmse : 0.0058\n",
      "LGBMRegressor model nrmse : 0.0063\n",
      "XGBRegressor model nrmse : 0.0055\n",
      "CAT 코드 실행 시간:         95s\n",
      "LGB 코드 실행 시간:          1s\n",
      "XGB 코드 실행 시간:          6s\n",
      "average model nrmse : 0.0057\n",
      "==============================\n",
      "Model Sum Average nrmse 0.0048\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import shuffle\n",
    "import lightgbm\n",
    "import joblib\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "\n",
    "skf = KFold(n_splits = 10, random_state = SEED, shuffle = True) #총 6번의 fold 진행\n",
    "n = 0 #x번째 fold인지 기록\n",
    "\n",
    "fold_target_pred = []\n",
    "fold_score = []\n",
    "\n",
    "#파일 디렉토리 생성\n",
    "model_dir = f'./model'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "for train_index, valid_index in skf.split(X): #label 기준으로 stratified k fold 진행\n",
    "    n += 1\n",
    "    \n",
    "    val_pred_name = [] #validation pred model 이름 저장\n",
    "    val_pred = []      #validation set pred 결과 저장\n",
    "    target_pred = []   #test set pred 결과 저장\n",
    "    \n",
    "    X_train, X_valid = X[train_index], X[valid_index]\n",
    "    y_train, y_valid = y.values[train_index], y.values[valid_index]\n",
    "    \n",
    "    ### Create Model ###\n",
    "    #CAT model\n",
    "    start_time_cat = time.time()\n",
    "    model_cat = CatBoostRegressor(verbose = 200,\n",
    "                            learning_rate = 0.02,\n",
    "                            random_seed = 42,\n",
    "                            iterations = 5000,\n",
    "                            loss_function='MultiRMSE',\n",
    "                            #ignored_features = [8, 9, 31, 32, 33, 34, 45, 50, 51, 53, 54, 55],\n",
    "                            od_wait = 200,\n",
    "                            depth = 9)\n",
    "    \n",
    "    model_cat.fit(X_train, y_train, eval_set=(X_valid, y_valid))\n",
    "    end_time_cat = time.time()\n",
    "\n",
    "    #model cat 저장\n",
    "    cat_path = './model/cat_{}'.format(n)\n",
    "    model_cat.save_model(cat_path)\n",
    "    \n",
    "    #model cat 불러오기\n",
    "    #model_cat.load_model(cat_path)\n",
    "    \n",
    "    val_pred_name.append(\"CatBoostRegressor\")  # 모델 이름 저장\n",
    "    val_pred.append(model_cat.predict(X_valid))   # validation set pred 결과 저장\n",
    "    target_pred.append(model_cat.predict(X_test)) # test set pred 결과 저장\n",
    "    \n",
    "    ### LGBM model\n",
    "    start_time_lgb = time.time()\n",
    "    model_lgbm = LGBMRegressor(n_estimators = 2000, \n",
    "                                               learning_rate = 0.01,\n",
    "                                               max_depth = 16,\n",
    "                                               min_child_samples = 56,\n",
    "                                               subsample = 0.4,\n",
    "                                               num_leaves = 160,\n",
    "                                               random_state = 42,\n",
    "                                               verbose=-1,\n",
    "                                               n_jobs = 8)\n",
    "\n",
    "    fit_params = dict(\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        eval_metric = \"rmse\",\n",
    "        )\n",
    "\n",
    "    model_lgbm.fit(X_train, y_train, **fit_params)\n",
    "    end_time_lgb = time.time()\n",
    "    val_pred_name.append(\"LGBMRegressor\")  # 모델 이름 저장\n",
    "    val_pred.append(model_lgbm.predict(X_valid))   # validation set pred 결과 저장\n",
    "    target_pred.append(model_lgbm.predict(X_test)) # test set pred 결과 저장\n",
    "    \n",
    "    #model lgbm 저장\n",
    "    lgbm_path = './model/lgbm_{}.pkl'.format(n)\n",
    "    \n",
    "    # save model\n",
    "    joblib.dump(model_lgbm, lgbm_path)\n",
    "    \n",
    "    #model lgbm 불러오기\n",
    "    #model_lgbm.load(lgbm_path)\n",
    "\n",
    "    ### XGB model\n",
    "    start_time_xgb = time.time()\n",
    "    model_xgb = XGBRegressor(objective = \"reg:squarederror\",\n",
    "                                                  n_estimators = 3000,\n",
    "                                                  random_state = 42,\n",
    "                                                  eval_metric = \"rmse\", \n",
    "                                                  learning_rate=0.006,\n",
    "                                                  subsample=0.75, \n",
    "                                                  colsample_bytree = 0.86,\n",
    "                                                  max_depth=9,\n",
    "                                                  tree_method='gpu_hist', \n",
    "                                                  gpu_id = 0)\n",
    "    \n",
    "    fit_params = dict(\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        )\n",
    "    \n",
    "    model_xgb.fit(X_train, y_train, verbose=0, **fit_params)\n",
    "    end_time_xgb = time.time()\n",
    "    val_pred_name.append(\"XGBRegressor\")  # 모델 이름 저장\n",
    "    val_pred.append(model_xgb.predict(X_valid))   # validation set pred 결과 저장\n",
    "    target_pred.append(model_xgb.predict(X_test)) # test set pred 결과 저장\n",
    "    \n",
    "    \n",
    "    #model xgb 저장\n",
    "    xgb_path = './model/xgb_{}.pkl'.format(n)\n",
    "    joblib.dump(model_xgb, xgb_path)\n",
    "    #model_xgb.save(xgb_path)\n",
    "    \n",
    "    #model xgb 불러오기\n",
    "    #model_xgb.load(xgb_path)\n",
    "  \n",
    "    ### average validation pred ###\n",
    "    preds = np.array(val_pred[0])\n",
    "    for i in range(1, len(val_pred)):\n",
    "        preds += val_pred[i]\n",
    "    preds = preds/len(val_pred)\n",
    "\n",
    "    ### average target pred ###\n",
    "    target_preds = target_pred[0]\n",
    "    for i in range(1, len(target_pred)):\n",
    "        target_preds += target_pred[i]\n",
    "    target_preds = target_preds/len(target_pred)\n",
    "    fold_target_pred.append(target_preds) # append final target pred\n",
    "    \n",
    "    print(\"========== fold %d ==========\" %(n))\n",
    "    for i in range(len(val_pred)):\n",
    "        print(\"%s model nrmse : %0.4f\" %(val_pred_name[i], mean_squared_error(y_valid, val_pred[i]) ** 0.5))\n",
    "        \n",
    "    print('CAT 코드 실행 시간: %10ds' % (end_time_cat - start_time_cat))\n",
    "    print('LGB 코드 실행 시간: %10ds' % (end_time_lgb - start_time_lgb))\n",
    "    print('XGB 코드 실행 시간: %10ds' % (end_time_xgb - start_time_xgb))\n",
    "    print(\"average model nrmse : %0.4f\" %(mean_squared_error(y_valid, preds) ** 0.5))\n",
    "    fold_score.append(mean_squared_error(y_valid, preds) ** 0.5)\n",
    "\n",
    "total_score = fold_score[0]\n",
    "for i in range(1, len(fold_score)):\n",
    "    total_score += fold_score[i]\n",
    "    \n",
    "total_score = total_score/len(fold_score)\n",
    "\n",
    "print(\"==============================\")\n",
    "print(\"Model Sum Average nrmse %0.4f\" %(total_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def euclidean_distance(row1, row2):\n",
    "\tdistance = 0.0\n",
    "\tdistance += (row1 - row2[0])**2\n",
    "\treturn sqrt(distance)\n",
    "\n",
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "\tdistances = list()\n",
    "\tfor train_row in train:\n",
    "\t\tdist = euclidean_distance(test_row, train_row)\n",
    "\t\tdistances.append((train_row, dist))\n",
    "\tdistances.sort(key=lambda tup: tup[1])\n",
    "\tneighbors = list()\n",
    "\tfor i in range(num_neighbors):\n",
    "\t\tneighbors.append(distances[i][0])\n",
    "\treturn neighbors\n",
    "\n",
    "def predict_classification(train, test_row, num_neighbors):\n",
    "\tneighbors = get_neighbors(train, test_row, num_neighbors)\n",
    "\toutput_values = [row[-1] for row in neighbors]\n",
    "\tprediction = max(set(output_values), key=output_values.count)\n",
    "\treturn prediction\n",
    "dataset = pd.concat([y, y_class], axis=1)\n",
    "dataset = dataset.values\n",
    "\n",
    "knnclassifier = KNeighborsClassifier(1)\n",
    "knnclassifier.fit(y.to_numpy().reshape(-1,1), y_class.to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import shuffle\n",
    "import lightgbm\n",
    "import joblib\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 6, random_state = SEED, shuffle = True) #총 6번의 fold 진행\n",
    "n = 0 #x번째 fold인지 기록\n",
    "KNN = 1\n",
    "fold_target_pred = []\n",
    "fold_score = []\n",
    "fold_f1 = []\n",
    "\n",
    "#파일 디렉토리 생성\n",
    "model_dir = f'./model'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "for train_index, valid_index in skf.split(X, y_class): #label 기준으로 stratified k fold 진행\n",
    "    n += 1\n",
    "    \n",
    "    val_pred_name = [] #validation pred model 이름 저장\n",
    "    val_pred = []      #validation set pred 결과 저장\n",
    "    target_pred = []   #test set pred 결과 저장\n",
    "    class_pred = []\n",
    "    \n",
    "    X_train, X_valid = X.values[train_index], X.values[valid_index]\n",
    "    y_train, y_valid = y.values[train_index], y.values[valid_index]\n",
    "    \n",
    "    y_class_valid = y_class.values[valid_index]\n",
    "    \n",
    "    ### Create Model ###\n",
    "    #CAT model\n",
    "    model_cat = CatBoostRegressor(verbose = 200,\n",
    "                            learning_rate = 0.02,\n",
    "                            random_seed = 42,\n",
    "                            iterations = 5000,\n",
    "                            loss_function='MultiRMSE',\n",
    "                            #ignored_features = [8, 9, 31, 32, 33, 34, 45, 50, 51, 53, 54, 55],\n",
    "                            od_wait = 200,\n",
    "                            depth = 9)\n",
    "\n",
    "    #model cat 저장\n",
    "    cat_path = './model/cat_{}'.format(n)\n",
    "    model_cat.load_model(cat_path)\n",
    "    val_pred_name.append(\"CatBoostRegressor\")  # 모델 이름 저장\n",
    "    cat_output = model_cat.predict(X_valid)\n",
    "    val_pred.append(cat_output)   # validation set pred 결과 저장\n",
    "    target_pred.append(model_cat.predict(X_test)) # test set pred 결과 저장\n",
    "    \n",
    "    p = knnclassifier.predict(cat_output.reshape(-1, 1))\n",
    "    \n",
    "    class_pred.append(p)\n",
    "    lgbm_path = './model/lgbm_{}.pkl'.format(n)\n",
    "    \n",
    "    ### LGBM model\n",
    "    model_lgbm = joblib.load(lgbm_path)\n",
    "    lgbm_output = model_lgbm.predict(X_valid)\n",
    "    val_pred_name.append(\"LGBMRegressor\")  # 모델 이름 저장\n",
    "    val_pred.append(lgbm_output)   # validation set pred 결과 저장\n",
    "    target_pred.append(model_lgbm.predict(X_test)) # test set pred 결과 저장\n",
    "    \n",
    "    p = knnclassifier.predict(lgbm_output.reshape(-1, 1))\n",
    "    class_pred.append(p)\n",
    "\n",
    "    #model lgbm 불러오기\n",
    "    #model_lgbm.load(lgbm_path)\n",
    "\n",
    "    ### XGB model\n",
    "    xgb_path = './model/xgb_{}.pkl'.format(n)\n",
    "    \n",
    "    model_xgb = joblib.load(xgb_path)\n",
    "    xgb_output = model_xgb.predict(X_valid)\n",
    "    val_pred_name.append(\"XGBRegressor\")  # 모델 이름 저장\n",
    "    val_pred.append(xgb_output)   # validation set pred 결과 저장\n",
    "    target_pred.append(model_xgb.predict(X_test)) # test set pred 결과 저장\n",
    "    \n",
    "    p = knnclassifier.predict(xgb_output.reshape(-1, 1))\n",
    "    class_pred.append(p)\n",
    "    \n",
    "    ### average validation pred ###\n",
    "    preds = np.array(val_pred[0])\n",
    "    for i in range(1, len(val_pred)):\n",
    "        preds += val_pred[i]\n",
    "    preds = preds/len(val_pred)\n",
    "    \n",
    "    total_class_output = knnclassifier.predict(preds.reshape(-1, 1))\n",
    "\n",
    "    ### average target pred ###\n",
    "    target_preds = target_pred[0]\n",
    "    for i in range(1, len(target_pred)):\n",
    "        target_preds += target_pred[i]\n",
    "    target_preds = target_preds/len(target_pred)\n",
    "    fold_target_pred.append(target_preds) # append final target pred\n",
    "    \n",
    "    print(\"========== fold %d ==========\" %(n))\n",
    "    for i in range(len(val_pred)):\n",
    "        print(\"%s model nrmse : %0.4f\" %(val_pred_name[i], mean_squared_error(y_valid, val_pred[i]) ** 0.5))\n",
    "        print(\"%s model F1-Macro : %0.4f\" %(val_pred_name[i], f1_score(y_class_valid, class_pred[i], average='macro')))\n",
    "        \n",
    "    print(\"average model nrmse : %0.4f\" %(mean_squared_error(y_valid, preds) ** 0.5))\n",
    "    print(\"average model F1-Macro : %0.4f\" %(f1_score(y_class_valid, total_class_output, average='macro')))\n",
    "    fold_score.append(mean_squared_error(y_valid, preds) ** 0.5)\n",
    "    fold_f1.append(f1_score(y_class_valid, total_class_output, average='macro'))\n",
    "\n",
    "total_score = fold_score[0]\n",
    "total_f1_score = fold_f1[0]\n",
    "for i in range(1, len(fold_score)):\n",
    "    total_score += fold_score[i]\n",
    "    total_f1_score += fold_f1[i]\n",
    "    \n",
    "total_score = total_score/len(fold_score)\n",
    "total_f1_score /= len(fold_score)\n",
    "\n",
    "print(\"==============================\")\n",
    "print(\"Model Sum Average nrmse %0.4f\" %(total_score))\n",
    "print(\"Model Sum Average F1 %0.4f\" %(total_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = np.array(fold_target_pred[0])\n",
    "\n",
    "for i in range(1, 6):\n",
    "    final_pred += fold_target_pred[i]\n",
    "\n",
    "final_pred = final_pred/6\n",
    "\n",
    "class_final_pred = knnclassifier.predict(final_pred.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submission file 준비\n",
    "submit = pd.read_csv('sample_submission.csv')\n",
    "submit['Y_Class'] = class_final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2e4a47e36f0811c316f759d1a92830bb55dbd78977c69f453a1e4981941b515"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
